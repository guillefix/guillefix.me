<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.17" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Naive Bayes: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Generative%20supervised%20learning " data-tags="[[Generative supervised learning]]" data-tiddler-title="Naive Bayes"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="tiddlymap" class="tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton " title="Toggle TiddlyMap actions">


</button></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Naive Bayes
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 4th November 2016 at 9:43am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Generative supervised learning
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>A <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generative%2520supervised%2520learning.html">Generative supervised learning</a> algorithm used when the input space is <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><msup><mo>}</mo><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">\{0,1\}^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">{</span><span class="mord mathrm">0</span><span class="mpunct">,</span><span class="mord mathrm">1</span><span class="mclose"><span class="mclose">}</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span>, so an input point consists of <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><mo>{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>}</mo></mrow><annotation encoding="application/x-tex">x_i \in \{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">∈</span><span class="mopen">{</span><span class="mord mathrm">0</span><span class="mpunct">,</span><span class="mord mathrm">1</span><span class="mclose">}</span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i=1,2,...,n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">i</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mpunct">,</span><span class="mord mathrm">2</span><span class="mpunct">,</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mpunct">,</span><span class="mord mathit">n</span></span></span></span></span>.</p><p>The particular variant below is called <strong>Multivariate Bernoulli event model</strong>, as it is part of a family of models called <strong>event models</strong> (another example of which is below).</p><p>Even though the assumptions in naive Bayes are too simplifying, the model often gives good results, because it isn't prone to <a class="tc-tiddlylink tc-tiddlylink-missing" href="Overfiting.html">Overfiting</a> due to the relatively small number of parameters. It is however, not very good as a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generative%2520model.html">Generative model</a>, but it does well as a classifier.</p><p>See <a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Naive_Bayes_classifier" rel="noopener noreferrer" target="_blank">Wiki</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;index=5&amp;list=PLA89DCFA6ADACE599#t=44m35s" rel="noopener noreferrer" target="_blank">Intro lec vid</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;index=5&amp;list=PLA89DCFA6ADACE599#t=48m39s" rel="noopener noreferrer" target="_blank">Definition of naive Bayes assumption</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;index=5&amp;list=PLA89DCFA6ADACE599#t=1h02m45s" rel="noopener noreferrer" target="_blank">Problem with Naive Bayes</a>. Probabilities <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>X</mi><mi mathvariant="normal">∣</mi><mi>Y</mi><mo>)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">P(X|Y)=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathrm">0</span></span></span></span></span> for <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07847em;">X</span></span></span></span></span>s that have never been observed, and this causes problems (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">P(Y|X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.22222em;">Y</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></span> undefined). <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;index=5&amp;list=PLA89DCFA6ADACE599#t=1h06m40s" rel="noopener noreferrer" target="_blank">How to fix it</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;index=5&amp;list=PLA89DCFA6ADACE599#t=1h09m10s" rel="noopener noreferrer" target="_blank">actually here</a>... (the method is known as <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Laplace%2520smoothing.html">Laplace smoothing</a>).</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;index=6&amp;list=PLA89DCFA6ADACE599#t=27m" rel="noopener noreferrer" target="_blank">Naive Bayes  is a linear classifier</a>, just like <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Gaussian%2520discriminant%2520analysis.html">Gaussian discriminant analysis</a>, it creates a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Hyperplane.html">Hyperplane</a> <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Classification.html">Classification</a> boundary, and a sigmoid posterior, like <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Logistic%2520regression.html">Logistic regression</a></p><h3 class=""><u>Generalization to when <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span> can take any of <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span></span> values</u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;index=6&amp;list=PLA89DCFA6ADACE599&amp;spfreload=1#t=3m25s" rel="noopener noreferrer" target="_blank">here</a>. Can arrise when discretizing a real valued <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span>.</p><h3 class=""><u>Variant for sequences (Multinomial event model)</u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;index=6&amp;list=PLA89DCFA6ADACE599&amp;spfreload=1#t=6m0s" rel="noopener noreferrer" target="_blank">here</a>. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;index=6&amp;list=PLA89DCFA6ADACE599&amp;spfreload=1#t=8m5s" rel="noopener noreferrer" target="_blank">description of model</a>.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;index=6&amp;list=PLA89DCFA6ADACE599#t=20m33s" rel="noopener noreferrer" target="_blank">This is the log likelihood</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;index=6&amp;list=PLA89DCFA6ADACE599&amp;spfreload=1#t=12m45s" rel="noopener noreferrer" target="_blank">Maximum likelihood estimates</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;index=6&amp;list=PLA89DCFA6ADACE599#t=14m55s" rel="noopener noreferrer" target="_blank">Laplace-smoothed estimate</a></p></div>


</div>

</p>

</section>
</body>
</html>
