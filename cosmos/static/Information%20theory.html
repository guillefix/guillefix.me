<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.15" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Information theory: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Information%20science"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Information theory
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 7th May 2018 at 11:46am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Information science
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p><strong>Information theory</strong></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/playlist?list=PLE125425EC837021F" rel="noopener noreferrer" target="_blank">Information Theory</a>, <a class="tc-tiddlylink-external" href="https://www.youtube.com/playlist?list=PLJfu_xpF92pvTfcJAILr5Kg1ptMvHUnft" rel="noopener noreferrer" target="_blank">Information Theory (CUHK)</a></p><h2 class="">Entropy/Information</h2><ul><li><strong>Asymptotic equipartition property</strong></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Information%2520measures.html">Information measures</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Data%2520processing%2520theorem.html">Data processing theorem</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Fano's%2520inequality.html">Fano's inequality</a></li></ul><h2 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Coding%2520theory.html">Coding theory</a></h2><p>A code is a representation of information/data. </p><p>Coding theory (and/or coding methods) is the study of the properties of codes and their fitness for a specific application. These applications include <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Data%2520transmission.html">Data transmission</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Data%2520compression.html">Data compression</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Cryptography.html">Cryptography</a>, and <a class="tc-tiddlylink tc-tiddlylink-missing" href="Network%2520information%2520theory.html">Network information theory</a></p><h2 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Data%2520transmission.html">Data transmission</a></h2><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Source-channel%2520separation%2520theorem.html">Source-channel separation theorem</a></p><p>The main problem of study in data transmission theory is: for a particular <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Communication%2520channel.html">Communication channel</a>, find code so that data transmission rate is as high as possible, while receiver receives the information with negligible probability of error.</p><p>The limit in data transmission rate turns out to be the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Channel%2520capacity.html">Channel capacity</a>, as established by the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Channel%2520coding%2520theorem.html">Channel coding theorem</a>.</p><p>Data transmission is part of the broader area of study called <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Communication%2520theory.html">Communication theory</a>, which includes consideration of the information source and destination.</p><h2 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Data%2520compression.html">Data compression</a></h2><p>Study of theoretical limits and implementation of codes that make average length of the value of a random variable as short as possible, whether in a lossless, or lossy way.</p><p>The limit in the average length of codewords in a lossless code turns out to be the entropy, as established  by the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Source%2520coding%2520theorem.html">Source coding theorem</a></p><p>Limits in lossy codes are established in <a class="tc-tiddlylink tc-tiddlylink-missing" href="Rate%2520compression%2520theory.html">Rate compression theory</a></p><h2 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Cryptography.html">Cryptography</a></h2><h2 class=""><a class="tc-tiddlylink tc-tiddlylink-missing" href="Network%2520information%2520theory.html">Network information theory</a></h2><h2 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Algorithmic%2520information%2520theory.html">Algorithmic information theory</a></h2><p><strong><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Kolmogorov%2520complexity.html">Kolmogorov complexity</a></strong>. Shortest program that will produced desired output in Turing machine. Occam's razor</p><hr><h3 class="">More related areas</h3><ul><li><strong>Ergodic theory</strong>. A dynamical system is ergodic if it has a unique probabliy distribution in the long time limit, I think Asymptotic equipartition theorem gives probability of each typical sequence.</li><li><strong>Hypothesis testing</strong> (See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Statistics.html">Statistics</a>).</li><li><strong><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Statistical%2520physics.html">Statistical mechanics</a></strong></li><li><strong><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Quantum%2520information%2520theory.html">Quantum information theory</a></strong></li><li><strong>Inference</strong>. Kolmogorov complexity is often applied to extrapolate from data. See also Solomonoff's algorithmic probability, and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Machine%2520learning.html">Machine learning</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Signal%2520processing.html">Signal processing</a></li><li><strong>Gambling and investment</strong>. Theory of investment in stock markets. See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Game%2520theory.html">Game theory</a>.<ul><li>Doubling rate. Has parallels with entropy</li></ul></li><li><strong><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Probability%2520theory.html">Probability theory</a></strong></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Sequence%2520space.html">Sequence space</a>s and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Symbolic%2520dynamics.html">Symbolic dynamics</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Complexity%2520theory.html">Complexity theory</a><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Descriptional%2520complexity.html">Descriptional complexity</a></li></ul></li></ul><hr><p><a class="tc-tiddlylink-external" href="http://worrydream.com/refs/Shannon - A Mathematical Theory of Communication.pdf" rel="noopener noreferrer" target="_blank">Shannon - A Mathematical Theory of Communication</a></p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S0166218X07002326" rel="noopener noreferrer" target="_blank">General theory of information transfer: Updated</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Entropy%2520reduction.html">Entropy reduction</a></p><p><a class="tc-tiddlylink-external" href="https://books.google.co.uk/books?hl=en&amp;lr=&amp;id=EZ6KAwAAQBAJ&amp;oi=fnd&amp;pg=PP5&amp;ots=bqpF4UZhji&amp;sig=fmxtdgsKYFUjKFcYDe9bxdoagFM#v=onepage&amp;q&amp;f=false" rel="noopener noreferrer" target="_blank">Storing and Transmitting Data: Rudolf Ahlswede’s Lectures on Information ...</a></p><p><a class="tc-tiddlylink-external" href="http://download.springer.com/static/pdf/860/bok%253A978-3-642-36899-8.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fbook%2F10.1007%2F978-3-642-36899-8&amp;token2=exp=1467511400~acl=%2Fstatic%2Fpdf%2F860%2Fbok%25253A978-3-642-36899-8.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fbook%252F10.1007%252F978-3-642-36899-8*~hmac=07f9d2ad15fce4ba4ad13e57c22b7ffbbbabc694ce1928057668a650bdd9c175" rel="noopener noreferrer" target="_blank">Information Theory, Combinatorics, and Search Theory</a></p><p><a class="tc-tiddlylink tc-tiddlylink-missing" href="Theory%2520of%2520identification.html">Theory of identification</a></p><p><a class="tc-tiddlylink tc-tiddlylink-missing" href="Theory%2520of%2520ordering.html">Theory of ordering</a> (see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Entropy%2520reduction.html">Entropy reduction</a>)</p><p><a class="tc-tiddlylink tc-tiddlylink-missing" href="Search%2520theory.html">Search theory</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/user/cse6222yorku/videos?view=0&amp;shelf_id=4&amp;sort=dd" rel="noopener noreferrer" target="_blank">YB videos</a>
– <a class="tc-tiddlylink-external" href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-050j-information-and-entropy-spring-2008/videos-homework-and-readings/" rel="noopener noreferrer" target="_blank">MIT videos</a></p><p><a class="tc-tiddlylink-external" href="http://ieeexplore.ieee.org/abstract/document/612919/" rel="noopener noreferrer" target="_blank">Back from infinity: a constrained resources approach to information theory</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/user/cse6222yorku/playlists" rel="noopener noreferrer" target="_blank">Video lectures</a></p></div>


</div>

</p>

</section>
</body>
</html>
