<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Initialization: Cosmos â€” All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists " data-tags="" data-tiddler-title="Initialization"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Initialization
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 13th May 2019 at 7:24pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Weight%2520initialization.html">Weight initialization</a></p><p><a class="tc-tiddlylink-external" href="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79" rel="noopener noreferrer" target="_blank">Introductory article</a>.</p><blockquote><p>The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network. <small>If either occurs, loss gradients will either be too large or too small to flow backwards beneficially, and the network will take longer to converge, if it is even able to do so at all.</small>.</p></blockquote><p>Initialization is very important for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Training.html">Training</a>, but it can also influence the inductive bias, and therefore affect <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generalization.html">Generalization</a>. I think in practice, it seems to matter more for the former, though.</p><p>Recipes on weight initialization, based on a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Mean%2520field%2520theory.html">Mean field theory</a> analysis of neural networks: <a class="tc-tiddlylink-external" href="http://papers.nips.cc/paper/6322-exponential-expressivity-in-deep-neural-networks-through-transient-chaos" rel="noopener noreferrer" target="_blank">Exponential expressivity in deep neural networks through transient chaos</a>. See <a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1711.00165" rel="noopener noreferrer" target="_blank">here</a> for extension to ReLU networks</p><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Exploding%2520gradients%2520problem.html">Exploding gradients problem</a></p><hr><p>Xavier, He, Lecun initializations..</p></div>



</div>

</p>
</section>
</body>
</html>
