<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.12" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Convolutional neural network: Cosmos â€” a non-linear personal web notebook</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   "><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible" title="More actions">


</button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible" title="Edit this tiddler">


</button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible" title="Close this tiddler">


</button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Convolutional neural network
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="guillefix.html">
guillefix
</a> 24th June 2016 at 1:56am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"></div>
</div>
<div class="tc-tiddler-body tc-reveal"><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10" rel="noopener noreferrer" target="_blank">Nando's vid</a></p><p><a class="tc-tiddlylink-external" href="http://cs231n.github.io/" rel="noopener noreferrer" target="_blank">http://cs231n.github.io/</a></p><p><a class="tc-tiddlylink-external" href="http://cs231n.github.io/convolutional-networks/" rel="noopener noreferrer" target="_blank">http://cs231n.github.io/convolutional-networks/</a></p><p><a class="tc-tiddlylink-external" href="http://cs231n.stanford.edu/syllabus.html" rel="noopener noreferrer" target="_blank">http://cs231n.stanford.edu/syllabus.html</a></p><h3 class=""><a class="tc-tiddlylink tc-tiddlylink-missing" href="http%253A%252F%252Fscs.ryerson.ca%252F~aharley%252Fvis%252Fconv%252F.html">Convnet demo on the web!</a> <a class="tc-tiddlylink tc-tiddlylink-missing" href="http%253A%252F%252Fscs.ryerson.ca%252F~aharley%252Fvis%252F.html">details here</a></h3><p><img src="http://scs.ryerson.ca/~aharley/vis/images/convnet_480.png"></p><p><img src="http://deeplearning.net/tutorial/_images/mylenet.png"></p><p><strong>Convolution</strong></p><p>In The &quot;c1 feature maps&quot; are a set of 2D arrays of neurons. Each array looks for a feature, and a point in the array would represent the location of that feature. To accomplish this, that point of that array is connected to a set of pixels centered in the corresponding point in the input image (an array of pixels). We have much less parameters because for each of these 2D arrays we only specify the parameters for one of the neruons in that array, all other neurons are identical, just connected to displaced sets of pixels.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=14m35s" rel="noopener noreferrer" target="_blank">What is convolution</a>. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=18m39s" rel="noopener noreferrer" target="_blank">Correlation</a>. Flip parameters vector (or array..) and rewrite the correlation, <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=21m50s" rel="noopener noreferrer" target="_blank">we get a convolution</a>. Of course, there's much more to <a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Convolution" rel="noopener noreferrer" target="_blank">convolutions</a>, including the convolution theorem for e.g.</p><p><strong>Stride</strong> How much you jump in pixel space (or in previous layer) when you move from one point to another in a feature layer.</p><p>Can also expand boundary (<em>zero padding</em>) to keep layer gotten by convolution is of same size as original layer.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=27m06s" rel="noopener noreferrer" target="_blank">Nice example</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=35m06s" rel="noopener noreferrer" target="_blank">So many indices!</a></p><p><strong>Pooling</strong></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=9m56s" rel="noopener noreferrer" target="_blank">This is what it does</a>. It downsamples. For memory, and invariance (being more insesitive to perturbations).</p><p>We can also apply non-linearities in between layers of course, like for contours enhacement</p><p>Use as many of these layers Iconvolutions and poolings) as we can train, 20+ (<a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning.html">Deep learning</a>)</p><p>At the end we may have a fully connected neural layer, to do the classification, but researchers are questioning if it is that useful..</p><p>We may <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=13m30s" rel="noopener noreferrer" target="_blank">visualize the features</a> in the feature maps by visualizing the matrices of parameters.</p><h3 class=""><u>Sentence <a class="tc-tiddlylink tc-tiddlylink-missing" href="ConvNets.html">ConvNets</a></u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bEUX_56Lojc&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=10#t=44m55s" rel="noopener noreferrer" target="_blank">Vid</a></p><p>Sentence <a class="tc-tiddlylink tc-tiddlylink-missing" href="DynConvNet.html">DynConvNet</a></p><p>Document models (Misha Denil)</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Natural%2520language%2520processing.html">Natural language processing</a></p><p><a class="tc-tiddlylink-external" href="http://www.vlfeat.org/matconvnet/" rel="noopener noreferrer" target="_blank">MatConvNet: CNNs for MATLAB</a></p></div>



</div>

</p>

</section>
</body>
</html>
