<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Recurrent neural network: Cosmos — All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists  tc-tagged-Artificial%20neural%20network" data-tags="[[Artificial neural network]]" data-tiddler-title="Recurrent neural network"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Recurrent neural network
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 25th March 2017 at 4:11pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Artificial neural network
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><h2 class=""><u>Basic RNNs</u></h2><p><strong><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=56TYLaQN4N8&amp;index=12&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=7m48s" rel="noopener noreferrer" target="_blank">Recurrent neural nets</a></strong>. Vanishing gradient problem, naively, RNNs don't give you long term memory.. so you have <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Long%2520short-term%2520memory.html">Long short-term memory</a> networks</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=mF5-tr7qAF4#t=21m25s" rel="noopener noreferrer" target="_blank">Recurrent neural networks -- Schmidhuber</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Jkkjy7dVdaY" rel="noopener noreferrer" target="_blank">Recurrent Neural Network Writes Music and Shakespeare Novels - Two Minute Papers</a></p><h3 class=""><u>The vanishing gradients problem</u></h3><p><a class="tc-tiddlylink-external" href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" rel="noopener noreferrer" target="_blank">Hochreiter1991</a> – <a class="tc-tiddlylink-external" href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" rel="noopener noreferrer" target="_blank">Bengio1994</a></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Long%2520short-term%2520memory.html">Long short-term memory</a></u></h2><p>Proposed to solve the vanishing gradients problem</p><p><a class="tc-tiddlylink-external" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener noreferrer" target="_blank">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><p>See also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Neural%2520networks%2520with%2520memory.html">Neural networks with memory</a>,  <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning.html">Deep learning</a></p><h2 class=""><u>Gated recurrent unit</u></h2><p>A variation of the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Long%2520short-term%2520memory.html">Long short-term memory</a> network</p><h2 class=""><u>More <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Augmented%2520RNN.html">Augmented RNN</a>s</u></h2><hr><p>Nice curated list of RNNs: <a class="tc-tiddlylink-external" href="https://github.com/kjw0612/awesome-rnn" rel="noopener noreferrer" target="_blank">https://github.com/kjw0612/awesome-rnn</a></p><hr><p><u><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1605.00064.pdf" rel="noopener noreferrer" target="_blank">Higher Order Recurrent Neural Networks</a></u> . We propose to use more memory
units to keep track of more preceding states
in recurrent neural networks (RNNs), which are
all recurrently fed to the hidden layers as feedback
through different weighted path</p></div>



</div>

</p>
</section>
</body>
</html>
