<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.17" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Free energy principle: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists    " data-tags="" data-tiddler-title="Free energy principle"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Free energy principle
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 12th February 2017 at 4:59pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"></div>
</div>
<div class="tc-tiddler-body tc-reveal"><p><a class="tc-tiddlylink-external" href="http://www.umsu.de/wo/2013/600" rel="noopener noreferrer" target="_blank">http://www.umsu.de/wo/2013/600</a></p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S092842570600060X" rel="noopener noreferrer" target="_blank">A free energy principle for the brain</a> – <a class="tc-tiddlylink-external" href="http://sci-hub.bz/10.1016/j.jphysparis.2006.10.001" rel="noopener noreferrer" target="_blank">pdf</a></p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S0022249615000759" rel="noopener noreferrer" target="_blank">A tutorial on the free-energy principle</a> (it's basically <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Bayesian%2520inference.html">Bayesian inference</a>)...</p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Free_energy_principle" rel="noopener noreferrer" target="_blank">https://www.wikiwand.com/en/Free_energy_principle</a></p><p>The free energy principle states that systems change to
decrease their free energy. The concept of free-energy arises
in many contexts, especially physics and statistics. In thermodynamics,
free energy is a measure of the amount of
work that can be extracted from a system, and is useful
in engineering applications. It is the difference between
the energy and the entropy of a system. Free-energy also
plays a central role in statistics, where, borrowing from statistical
thermodynamics; approximate inference by variational
free energy minimization (also known as
variational Bayes, or ensemble learning) has maximum
likelihood and maximum a posteriori methods as special
cases. It is this sort of free energy, which is a measure of
statistical probability distributions; we apply to the
exchange of biological systems with the world. The implication
is that these systems make implicit inferences about
their surroundings.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=zWFfZHqOnvM" rel="noopener noreferrer" target="_blank">Karl Friston talk</a>. Systems that have certain measurable characteristics which persist in time, and are thus ergodic in this certain weak sense. This implies the existence of a random global attractor (<a class="tc-tiddlylink tc-tiddlylink-missing" href="Ergodic%2520theorem.html">Ergodic theorem</a>).</p><p><a class="tc-tiddlylink-external" href="http://www.fil.ion.ucl.ac.uk/~karl/Free%20Energy%20Value%20and%20Attractors.pdf" rel="noopener noreferrer" target="_blank">Free Energy, Value, and Attractors</a></p><p><u>Universal Lyapunov function?</u></p><table><tbody><tr class="evenRow"><td align="left"><span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mrow><mi>x</mi></mrow><mo>˙</mo></mover><mo>=</mo><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>+</mo><mi>ω</mi></mrow><annotation encoding="application/x-tex">\dot{x} = f(x) + \omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle cramped"><span class="mord mathit">x</span></span></span><span style="top:0em;margin-left:0.05556em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="accent-body"><span>˙</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.03588em;">ω</span></span></span></span></span></td><td>Steady state: <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mo>(</mo><mi mathvariant="normal">Γ</mi><mo>+</mo><mi>Q</mi><mo>)</mo><mi mathvariant="normal">∇</mi><mi>ln</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">f(x)=(\Gamma + Q) \nabla \ln p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord mathrm">Γ</span><span class="mbin">+</span><span class="mord mathit">Q</span><span class="mclose">)</span><span class="mord mathrm">∇</span><span class="mop">ln</span><span class="mord mathit">p</span></span></span></span></span></td><td align="right">Lyapunov function: <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mi>ln</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">-\ln p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord">−</span><span class="mop">ln</span><span class="mord mathit">p</span></span></span></span></span></td></tr></tbody></table><p><span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">ω</span></span></span></span></span> are random fluctuations, <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span></span> is deterministic flow. <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span></span></span></span></span> is steady state probability. In short, this equation rep-resents “a simple starting point for statistical mechanics and thermodynamics and is consistent with conservative dynam-ics that dominates the physical sciences”. See below for details and derivations.</p><p><u>Surprisal is a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Lyapunov%2520function.html">Lyapunov function</a> of the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Fokker-Planck%2520equation.html">Fokker-Planck equation</a></u></p><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Surprisal%2520as%2520a%2520Lyapunov%2520function%2520in%2520stochastic%2520dynamics.html">Surprisal as a Lyapunov function in stochastic dynamics</a></p><p>Flow can be decomposed into a curl-free part increases value while the (con-servative) divergence-free part follows isoprobability con-tours and does not change value. This means every policy (expec-ted flow) reduces surprise as a function of time. In other words, it must direct flow towards states that are more probable (in the steady state), and have a greater sojourn time. This just describes how systems approach the steady state. They do so by uniformly increasing their steady state probability. This corresponds to a decrease in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Entropy.html">Entropy</a>. However, the fluctuation due to <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">ω</span></span></span></span></span> causes a corresponding increase in that means that in steady state entropy is constant, as expected.</p><hr><p><a class="tc-tiddlylink-external" href="http://www.fil.ion.ucl.ac.uk/~karl/Free%20Energy%20Value%20and%20Attractors.pdf" rel="noopener noreferrer" target="_blank">Free Energy, Value, and Attractors</a>. <sub>We will compare and contrast two perspectives; one based upon a free energy principle [1] and the other on opti-mal control and reinforcement-learning [2–5]. policies can be cast as beliefs about the state-transitions that determine free energy.</sub></p><p>The main conclusion of this paper is that it is sufficient to minimise the average surprise (conditional entropy) of an agent’s states to explain adaptive behaviour. This can be achieved by policies or empirical priors (equations of motion) that guide action and induce random attractors in its state-space. These attract agents to (low-cost) invariant sets of states and lead to autopoietic and ergodic behaviour. </p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Active%2520inference.html">Active inference</a>. connection between empirical priors and policies. </p><hr><h2 class=""><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S092842570600060X" rel="noopener noreferrer" target="_blank">A free energy principle for the brain</a></h2><p>The system can minimise free energy by changing its con-
figuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and
perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems.</p><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Philosophy.html">Philosophy</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Science%2520and%2520Art.html">Science and Art</a></p><p>There is something
quite remarkable about the fact that our inferences about
the world, both perceptual and scientific, can be applied
to the very process of making those inferences (<a class="tc-tiddlylink tc-tiddlylink-resolves" href="Strange%2520loop.html">Strange loop</a>)</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Hierarchical%2520inference.html">Hierarchical inference</a></p><h3 class=""><u>Mathematical description</u></h3><p><em>Ensemble density</em>: <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi><mo>(</mo><mi>θ</mi><mo separator="true">;</mo><mi>λ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">q(\theta;\lambda)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mpunct">;</span><span class="mord mathit">λ</span><span class="mclose">)</span></span></span></span></span>. 
This is some arbitrary density function on the environments
parameters that is specified or encoded by the
systems parameters (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span></span>)</p><p>two other sets of variables that
describe, respectively, the effect of the environment on
the system and the effect of the system on the environment.
We will denote these as <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mrow><mi>y</mi></mrow><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">\tilde{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.6678599999999999em;"></span><span class="strut bottom" style="height:0.8622999999999998em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span><span style="top:-0.35em;margin-left:0.11112em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="accent-body"><span>~</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span></span>, respectively.</p><p>We also need to define a generative density <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mover accent="true"><mrow><mi>y</mi></mrow><mo>~</mo></mover><mo separator="true">,</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\tilde{y}, \theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span><span style="top:-0.35em;margin-left:0.11112em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="accent-body"><span>~</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span>, which defines a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generative%2520model.html">Generative model</a> of sensory inputs and causes.</p><p>See more <a class="tc-tiddlylink-external" href="http://sci-hub.bz/10.1016/j.jphysparis.2006.10.001" rel="noopener noreferrer" target="_blank">in paper</a> <mark>What is the meaning of this definition of free energy?</mark> It is a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Relative%2520entropy.html">Kullback-Leibler divergence</a></p><p>The free energy principle states that all the quantities
that can change; i.e., that are owned by the system (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span></span>, and <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span></span>), will change to minimise free energy.</p><p>Minimizing w.r.t system parameters results in <em>perception</em>: it results in the ensemble density to correspond to the <a class="tc-tiddlylink tc-tiddlylink-missing" href="A%2520posteriori%2520distribution.html">A posteriori distribution</a> of the causes given for the given sensory input.</p><p>Mininmizing w.r.t action parameters results in <em>action</em>: it enforces a sampling of the environment that is consistent with the ensemble density. In other words, the system will reconfigure itself
to sample sensory inputs that are the most likely
under the ensemble density.</p><dl><dd>There are at least two fundamental problems with the simple picture just outlined. One is that it makes little sense without postulating an independent source of goals or desires. Suppose it's true that I reach out for the pizza because I hallucinate (as it were) that that's what I'm doing, and I try to turn this hallucination into reality. Where does the hallucination come from? Surely it's not just a technical glitch in my perceptual system. Otherwise it would be a miraculous coincidence that I mostly hallucinate pleasant and fitness-increasing states. Some further part of my cognitive architecture must trigger the hallucinations that cause me to act. (If there's no such source, the much discussed &quot;dark room problem&quot; arises: why don't we efficiently minimize sensory surprise (and thereby free energy) by sitting still in a dark room until we die?)</dd><dd>The second problem is that efficient action requires keeping track of both the actual state and the goal state. If I want to reach out for the pizza, I'd better know where my arms are, where the pizza is, what's in between the two, and so on. If my internal representation of the world falsely says that the pizza is already in my mouth, it's hard to explain how I manage to grab it from the plate.</dd></dl><p>See <a class="tc-tiddlylink-external" href="http://www.umsu.de/wo/2013/600" rel="noopener noreferrer" target="_blank">here</a></p><dl><dd>-&gt;A closer look at Friston's papers suggests that the above rough proposal isn't quite what he has in mind. Recall that minimizing free energy can be seen as an approximate method for bringing one probability function Q close to another function P. If we think of Q as representing the system's beliefs about the present state, and P as a representation of its goals, then we have the required two components for explaining action. What's unusual is only that the goals are represented by a probability function, rather than (say) a utility function.</dd></dl><p>That version of the story looks much more plausible, and much less revolutionary, than the story outlined above. In the present version, perception and action are not two means to the same end – minimizing free energy. The free energy that's minimized in perception is a completely different quantity than the free energy that's minimized in action. What's true is that both tasks involve mathematically similar optimization problems. But that isn't too surprising given the well-known mathematical and computational parallels between conditionalizing and maximizing expected utility.</p><hr><p><img src="http://d10k7sivr61qqr.cloudfront.net/content/royinterface/10/86/20130475/F1.large.jpg"></p><p>Applications to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Neuroscience.html">Neuroscience</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Self-organization.html">Self-organization</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Intelligence.html">Intelligence</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Reinforcement%2520learning.html">Reinforcement learning</a></p><p><a class="tc-tiddlylink-external" href="http://www.fil.ion.ucl.ac.uk/~karl/" rel="noopener noreferrer" target="_blank">http://www.fil.ion.ucl.ac.uk/~karl/</a></p></div>


</div>

</p>

</section>
</body>
</html>
