<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.15" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>KNN: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Regression%20analysis"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
KNN
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 5th August 2018 at 12:38am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Regression analysis
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>k-Nearest neighbours</p><h3 class=""><a class="tc-tiddlylink-external" href="https://youtu.be/i2bt4vt908g?t=39m5s" rel="noopener noreferrer" target="_blank">Main result of error rate analysis of k-NN regression</a></h3><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Nearest-neighbour%2520classification.html">Nearest-neighbour classification</a></p><p>Nearest-neighbor methods: To get the prediction Ŷ for a point <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span></span>, use [those observations (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span></span> of them) in the training set T, closest in input space to point x]. Remember training set is a set of pairs <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">(</span><span class="mord mathit">x</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span></span>. Closest often refers to Euclidean distance.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=i2bt4vt908g&amp;index=4&amp;list=PLhuJd8bFXYJtxv2Y9ZoX7vClP96M28VnW" rel="noopener noreferrer" target="_blank">Lecture about theoretical analysis and understanding of k-NN</a></p><p>Can alsu use for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Regression.html">Regression</a> <a class="tc-tiddlylink tc-tiddlylink-resolves" href="KNN.html">KNN</a></p><p>It turns out that the <em>effective number of parameters</em> of k-nearest neighbors is <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mi mathvariant="normal">/</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">N/k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span></span>, even if technically there is only one parameter, <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span></span>.</p><p>Interactive app: <a class="tc-tiddlylink-external" href="https://github.com/lettier/interactiveknn" rel="noopener noreferrer" target="_blank">https://github.com/lettier/interactiveknn</a></p><p><a class="tc-tiddlylink-external" href="https://youtu.be/i2bt4vt908g" rel="noopener noreferrer" target="_blank">Unbounded capacity but it generalizes at non-trivial rate</a>. Indeed in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Nonparametric%2520statistics.html">Nonparametric statistics</a>, <mark>overparametrization isn't incompatible with <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generalization.html">Generalization</a></mark>!</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="No%2520free%2520lunch%2520theorem.html">Of course</a>, we need to assume something about the target function, typically <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Lipschitz.html">Lipschitz continuity</a>, <a class="tc-tiddlylink-external" href="https://youtu.be/i2bt4vt908g" rel="noopener noreferrer" target="_blank">but also other assumptions</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Curse%2520of%2520dimensionality.html">Curse of dimensionality</a></p><hr><p>–&gt; To me it seems more like a method in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Nonparametric%2520statistics.html">Nonparametric statistics</a>! Indeed it is (see <a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Nonparametric_statistics#Non-parametric_models" rel="noopener noreferrer" target="_blank">Wiki</a>).</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=44jq6ano5n0&amp;list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&amp;index=13" rel="noopener noreferrer" target="_blank">Classification w/ K Nearest Neighbors Intro - Practical Machine Learning Tutorial with Python p.13</a></p><p>A KNN classifier with K=1 induces a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Voronoi%2520tessellation.html">Voronoi tessellation</a>
</p></div>


</div>

</p>

</section>
</body>
</html>
