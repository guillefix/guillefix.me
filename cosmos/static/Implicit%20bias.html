<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Implicit bias: Cosmos — All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists  tc-tagged-Deep%20learning%20theory tc-tagged-Regularization" data-tags="[[Deep learning theory]] Regularization" data-tiddler-title="Implicit bias"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Implicit bias
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 5th December 2017 at 12:44am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Deep learning theory
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Regularization
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning%2520theory.html">Deep learning theory</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generalization%2520in%2520deep%2520learning.html">Generalization in deep learning</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1710.10345.pdf" rel="noopener noreferrer" target="_blank">THE IMPLICIT BIAS OF GRADIENT DESCENT ON SEPARABLE DATA</a> –  in deep learning we often benefit from implicit bias even when optimizing the (unregularized) training error to convergence, using stochastic or batch methods. For loss functions with attainable, finite, minimizers, such as the squared loss, we have some understanding of this: In particular, when minimizing an underdetermined least squares problem using gradient descent starting from the origin, we know we will <strong>converge to the minimum Euclidean norm solution</strong>. But the logistic loss, and its generalization the cross-entropy loss which is often used in deep learning, do not admit a finite minimizer on separable problems. Instead, to drive the loss toward zero and thus minimize it, the predictor must diverge toward infinity.</p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1709.01953.pdf" rel="noopener noreferrer" target="_blank">Implicit regularization in deep learning</a></p><hr><p>But we didn't tell the network to minimize the path norm (complexity). <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=ACdjYP0-cMw#t=39m5s" rel="noopener noreferrer" target="_blank">So where is the regularization coming from?</a>. He thinks it's the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Optimization.html">Optimization</a> algorithm that is biasing us towards simple global optima (work on this for convex opti?), but couldn't it be a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Genotype-phenotype%2520map.html">GP map</a>-like <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Simplicity%2520bias.html">Simplicity bias</a>. He approaches it from <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Geometry.html">Geometry</a>. I think he is right in that the algorithm plays a role in biasing. But GP bias probably does also, or it could at least be seized (as in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Neuroevolution.html">Neuroevolution</a> with indirect encodings..)</p><hr></div>



</div>

</p>
</section>
</body>
</html>
