<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.17" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Superintelligence: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Philosophy%20of%20AI " data-tags="[[Philosophy of AI]]" data-tiddler-title="Superintelligence"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Superintelligence
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 9th June 2018 at 5:03pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Philosophy of AI
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>See Nick Bostrom's book &quot;Superintelligence&quot;</p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1202.6177" rel="noopener noreferrer" target="_blank">Can Intelligence Explode?</a></p><p><a class="tc-tiddlylink-external" href="https://medium.com/@francois.chollet/the-impossibility-of-intelligence-explosion-5be4a9eda6ec" rel="noopener noreferrer" target="_blank">https://medium.com/@francois.chollet/the-impossibility-of-intelligence-explosion-5be4a9eda6ec</a> – <a class="tc-tiddlylink-external" href="https://www.facebook.com/guillermovalleperez/posts/10156139287091223" rel="noopener noreferrer" target="_blank">https://www.facebook.com/guillermovalleperez/posts/10156139287091223</a></p><hr><p>From <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Godel%252C%2520Escher%252C%2520Bach.html">GEB</a></p><p>Question: Will Al programs ever become &quot;superintelligent&quot;?</p><p>Speculation: I don't know. It is not clear that we would be able to understand or relate to a &quot;superintelligence&quot;, or that the con cept even makes sense. For instance, our own intelligence is tied in with our speed of thought. If our reflexes had been ten times faster or slower, we might have developed an entirely different set of concepts with which to describe the worl d. A creature with a radically different view of the world may simply not have ma ny points of contact with us. I have often wondered if there could be, for instance, pi eces of music which are to Bach as Bach is to folk tunes: &quot;Bach squared&quot;, so to speak. And would I be able to understand them? Maybe there is such music around me already, and I just don't recognize it, just as dogs don't understand language. The idea of superintelligence is very strange. In any case, I don't think of it as th e aim of Al research, although if we ever do reach the level of human intelligence, superintelligence will undoubtedly be the next goal-not only for us, but for our Al-program colleagues, too, who will be equally curious about Al and superinte lligence. It seems quite likely that Al programs will be extremely curious about Al in general-understandably. </p></div>


</div>

</p>

</section>
</body>
</html>
