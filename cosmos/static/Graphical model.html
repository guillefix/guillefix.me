<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.17" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Graphical model: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Machine%20learning tc-tagged-Probabilistic%20model " data-tags="[[Machine learning]] [[Probabilistic model]]" data-tiddler-title="Graphical model"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Graphical model
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 28th December 2017 at 11:39pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Machine learning
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
<span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Probabilistic model
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>A <strong>probabilistic graphical model</strong> is a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Model.html">Model</a> to represent a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Joint%2520probability%2520distribution.html">Joint probability distribution</a> (joint PD) of a set of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Random%2520variable.html">Random variable</a>s, which takes into account <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Causality.html">causal</a> relations, and dependencies. The models are called graphical, because these dependencies are represented using <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Graph.html">Graph</a>s, which allow for building the sparsely-parametrized representations of the joint PDs, and for many useful <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Algorithms.html">Algorithms</a> for inference and learning to be used.</p><p><u>Factors</u> are functions of the random variables, which are used to build the joint PD. One can do conditioning/reduction and marginalization on these factors. The reduction operation is like currying in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Functional%2520programming.html">Functional programming</a></p><p><a class="tc-tiddlylink-external" href="http://cs.brown.edu/courses/cs242/lectures/" rel="noopener noreferrer" target="_blank">http://cs.brown.edu/courses/cs242/lectures/</a></p><h1 class=""><u>Representation</u></h1><p><a class="tc-tiddlylink-external" href="https://www.coursera.org/learn/probabilistic-graphical-models/home" rel="noopener noreferrer" target="_blank">Coursera course</a> – <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bPGr5kFQbaw" rel="noopener noreferrer" target="_blank">Knowledge engineering</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Graph.html">Graph</a>s:</p><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Markov%2520network.html">Undirected graphical model</a></li><li>Directed graphical models, or <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Bayesian%2520network.html">Bayesian network</a>s –&gt; <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Hidden%2520Markov%2520model.html">Hidden Markov model</a></li></ul><p>See <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=ZYUnyyVgtyA&amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;index=25#t=7m10s" rel="noopener noreferrer" target="_blank">here</a> for the distinction of directed vs undirected graphical models. The difference, is that a directed graphical model is an undirected one, but where the factors that correspond to the edges, are normalized, because they correspond to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Conditional%2520probability.html">Conditional probability</a>es</p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Bayesian%2520network.html">Directed graphical models</a></u> (Bayesian nets)</h2><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-missing" href="Template%2520model.html">Template model</a>s</u></h3><p>Ways of representing graphical models that have a lot of internal shared structure (repeated variables and topologies), like events that occur over time, or relation types found over and over in a graph.. See <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=ogs4Oj8KahQ&amp;index=13&amp;list=PL50E6E80E8525B59C" rel="noopener noreferrer" target="_blank">vid</a></p><ul><li>Temporal models for temporal processes.<ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Dynamic%2520Bayesian%2520network.html">Dynamic Bayesian network</a>s <ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Hidden%2520Markov%2520model.html">Hidden Markov model</a></li></ul></li></ul></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Object-relational%2520model.html">Object-relational model</a>s<ul><li>Directed: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Plate%2520model.html">Plate model</a>s</li><li>Undirected</li></ul></li></ul><p>An importance class are those that show <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=gkRBlXj8h-w&amp;index=24&amp;list=PL50E6E80E8525B59C" rel="noopener noreferrer" target="_blank">Structured CPD</a>s</p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Markov%2520network.html">Undirected graphical models</a></u> (Markov nets)</h2><h3 class=""><u>Independencies</u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=obhBzPaESes&amp;list=PL50E6E80E8525B59C&amp;index=32" rel="noopener noreferrer" target="_blank">I-maps and perfect maps</a>.</p><p>An <a class="tc-tiddlylink tc-tiddlylink-resolves" href="I-map.html">I-map</a> (independence map) for a probability distribution <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span></span></span></span></span> is any graphical model <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span></span></span></span></span> such that the set of independencies implied by the network (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo>(</mo><mi>G</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">I(G)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathit">G</span><span class="mclose">)</span></span></span></span></span>) is a subset of the set of independences of <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span></span></span></span></span> (<span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo>(</mo><mi>P</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">I(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span></span>) (see <a class="tc-tiddlylink-external" href="http://courses.cms.caltech.edu/cs155/slides/cs155-03-dseparation-marked.pdf" rel="noopener noreferrer" target="_blank">here</a>), i.e. <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo>(</mo><mi>G</mi><mo>)</mo><mo>⊂</mo><mi>I</mi><mo>(</mo><mi>P</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">I(G) \subset I(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathit">G</span><span class="mclose">)</span><span class="mrel">⊂</span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span></span></p><p>A perfect (independence) map is one such that <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo>(</mo><mi>G</mi><mo>)</mo><mo>=</mo><mi>I</mi><mo>(</mo><mi>P</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">I(G) = I(P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathit">G</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span></span></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Sum-product%2520network.html">Sum-product network</a>s</u></h2><h1 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Inference%2520in%2520graphical%2520models.html">Inference</a></u></h1><h3 class=""><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Qa04kw1gKHk&amp;list=PL50E6E80E8525B59C&amp;index=36" rel="noopener noreferrer" target="_blank">Conditional Probability Queries</a> </h3><p>–  <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Qa04kw1gKHk&amp;list=PL50E6E80E8525B59C&amp;index=36#t=2m" rel="noopener noreferrer" target="_blank">Exact inference and even approximate inference are</a> <a class="tc-tiddlylink tc-tiddlylink-resolves" href="NP-hard.html">NP-hard</a>. <small>This comes about because the sum-product calculation over all possibilities when doing <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Marginalization.html">Marginalization</a> involves exponentially many terms</small>. However, this is for worst case, and for <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Qa04kw1gKHk&amp;list=PL50E6E80E8525B59C&amp;index=36#t=4m40s" rel="noopener noreferrer" target="_blank">general/average cases, there are practical inference algorithms!</a> </p><ul><li><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Qa04kw1gKHk&amp;list=PL50E6E80E8525B59C&amp;index=36#t=6m30s" rel="noopener noreferrer" target="_blank">Basic inference</a></li><li><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Qa04kw1gKHk&amp;list=PL50E6E80E8525B59C&amp;index=36#t=8m50s" rel="noopener noreferrer" target="_blank">Inference with evidence</a>, use <a class="tc-tiddlylink tc-tiddlylink-missing" href="Baye's%2520theorem.html">Baye's theorem</a></li></ul><h3 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Maximum%2520a%2520posteriori.html">Maximum a posteriori</a> inference</h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bL9Fvz3fx4c&amp;index=37&amp;list=PL50E6E80E8525B59C" rel="noopener noreferrer" target="_blank">video</a>. Hm, what about MAP, not {over all unobserved variables}?, i.e. with some marginalization... In any case this is also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="NP-hard.html">NP-hard</a></p><h2 class=""><u>Algorithms</u></h2><h3 class=""><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Qa04kw1gKHk&amp;list=PL50E6E80E8525B59C&amp;index=36#t=14m" rel="noopener noreferrer" target="_blank">Probability query algorithms</a></h3><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Variable%2520elimination.html">Variable elimination</a>, using <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Dynamic%2520programming.html">Dynamic programming</a></li><li>Message passing<ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Belief%2520propagation.html">Belief propagation</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Variational%2520inference.html">Variational inference</a></li></ul></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Monte%2520Carlo.html">Monte Carlo</a> methods, random sampling..<ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Markov%2520chain%2520Monte%2520Carlo.html">Markov chain Monte Carlo</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Importance%2520sampling.html">Importance sampling</a></li></ul></li></ul><h3 class=""><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=bL9Fvz3fx4c&amp;index=37&amp;list=PL50E6E80E8525B59C#t=7m18s" rel="noopener noreferrer" target="_blank">Maximum a posteriori algorithms</a></h3><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Variable%2520elimination.html">Variable elimination</a></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Message%2520passing.html">Message passing</a><ul><li>Max-product <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Belief%2520propagation.html">Belief propagation</a></li></ul></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Integer%2520programming.html">Integer programming</a> methods</li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Graph-cut.html">Graph-cut</a> methods, and other <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Graph%2520algorithms.html">Graph algorithms</a>s</li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Combinatorial%2520search.html">Combinatorial search</a></li></ul><p>Other <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Optimization.html">Optimization</a> algorithms.</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Viterbi%2520algorithm.html">Viterbi algorithm</a></p><h1 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Graphical%2520model%2520learning.html">Learning</a></u></h1><hr><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=WPSQfOkb1M8&amp;list=PL50E6E80E8525B59C" rel="noopener noreferrer" target="_blank">1.0 - Welcome-Probabilistic Graphical Models - Professor Daphne Koller</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/channel/UCvPnLF7oUh4p-m575fZcUxg/videos" rel="noopener noreferrer" target="_blank">Jeffrey A. Bilmes</a></p><p><u><a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Graphical_model" rel="noopener noreferrer" target="_blank">Graphical models</a></u></p><p>They can often be represented as kinds of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">Artificial neural network</a>s</p><p><a class="tc-tiddlylink-external" href="http://mpawankumar.info/teaching/cdt-optimization/lecture2_2.pdf" rel="noopener noreferrer" target="_blank">Energy minimization</a></p><h3 class=""><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=btr1poCYIzw" rel="noopener noreferrer" target="_blank">Composing graphical models with neural networks</a></h3><p><a class="tc-tiddlylink-external" href="https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/" rel="noopener noreferrer" target="_blank">https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/</a></p></div>


</div>

</p>

</section>
</body>
</html>
