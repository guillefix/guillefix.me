<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.17" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Supervised learning: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Machine%20learning " data-tags="[[Machine learning]]" data-tiddler-title="Supervised learning"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="tiddlymap" class="tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton " title="Toggle TiddlyMap actions">


</button></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Supervised learning
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 29th November 2017 at 8:16am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Machine learning
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p><em>aka predictive learning</em></p><p>The goal is to learn a mapping from inputs <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span></span> to outputs <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span></span>, given a labeled set of input-output pairs <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>=</mo><mo>{</mo><mo>(</mo><msup><mi>x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>y</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>)</mo><msubsup><mo>}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow><annotation encoding="application/x-tex">D = \{(x^{(i)}, y^{(i)})\}_{i=1}^N </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:1.146664em;vertical-align:-0.258664em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="mrel">=</span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="vlist"><span style="top:0.258664em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span>. Here <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span></span> is called the <strong>training set</strong>, and <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span></span></span> is the number of training examples.</p><p>Training data consisting on <strong>inputs and outputs</strong>.
<small>Other names for inputs: predictors, independent variables, features, attributes, covariates. Other names for outputs: responses, response variables, dependent variables.</small></p><p>In supervised learning, we want to find function relating inputs to outputs, to then be able to predict new outputs from new inputs. Often, we need <strong>a way to represent the function approximation</strong>, with some parameters (the <strong>model</strong>; with some subtleties for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Nonparametric%2520statistics.html">non-parametric</a> ones) and a <strong>learning algorithm</strong> to find best parameters for the data, so that the model can predict well. </p><p>– See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Learning%2520theory.html">Learning theory</a>, to learn about the way learning algorithms work, overfitting, underfitting, generalization  <strong>model selection</strong>, etc.. </p><p>New paradigm: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning.html">Deep learning</a></p><h2 class=""><u>Types of supervised learning algorithms</u></h2><h3 class=""><u><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=oTtow2Ui8vg&amp;index=5&amp;list=PLD0F06AA0D2E8FFBA" rel="noopener noreferrer" target="_blank">Generative vs discriminative models</a></u>.</h3><p>See below</p><h3 class=""><u>Parametric vs non-parametric model</u></h3><ul><li><strong>Parametric</strong>. There is a fixed number of parameters that the algorithm fits.</li><li><strong>Non-parametric</strong>. Formally, the number of &quot;parameters&quot; grows with the training set. Here number of parameters basically refers to &quot;amount of information in learned  function&quot;. For See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Nonparametric%2520statistics.html">Nonparametric statistics</a> An example is <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Nearest-neighbour%2520classification.html">Nearest-neighbour classification</a>.</li></ul><h3 class=""><u>Continuous vs categorical output</u></h3><p><em>Categorical</em>, or <em>nominal</em>. Output <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span></span> belongs to some finite <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Set.html">Set</a>. The learning problem is called <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Classification.html">Classification</a>.</p><p><em>continuous</em>. <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span></span> is a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Real%2520number.html">Real number</a>, or belongs to <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>R</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">R^n </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span> more generally. Learning is then known as <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Regression%2520analysis.html">Regression</a>.</p><p><em>ordinal</em>. When the output belongs to some set with some natural <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Ordering.html">Ordering</a>. Learning is then known as <em>ordinal ordering</em></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Regression%2520analysis.html">Regression</a></u></h2><p>Output value is continuous, and quantiative (i.e. it has an ordering, and a notion of closeness (matrix)).</p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Classification.html">Classification</a></u></h2><p>Output value is discrete, or categorical, or qualitative. No implicit ordering, or closeness on the variables. Simple approach: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Logistic%2520regression.html">Logistic regression</a></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Discriminative%2520learning.html">Discriminative learning</a></u></h2><p>Learning the function <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi mathvariant="normal">∣</mi><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\text{output}|\text{input})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="text mord textstyle uncramped"><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mord mathrm">∣</span><span class="text mord textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mclose">)</span></span></span></span></span>. See <a class="tc-tiddlylink-external" href="http://cs229.stanford.edu/notes/cs229-notes1.pdf" rel="noopener noreferrer" target="_blank">notes</a></p><h2 class=""><u>Structured learning</u></h2><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Structured_prediction" rel="noopener noreferrer" target="_blank">wiki</a>.</p><p>Often this actually deals with problems where input space has a different structure than a vector space (<a class="tc-tiddlylink-external" href="https://youtu.be/SFxypsvhhMQ?t=28m17s" rel="noopener noreferrer" target="_blank">video</a>)</p><h3 class=""><u>General methods</u></h3><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generalized%2520linear%2520model.html">Generalized linear model</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">Artificial neural network</a> (see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning.html">Deep learning</a>)</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Support%2520vector%2520machine.html">Support vector machine</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Decision%2520tree.html">Decision tree</a></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generative%2520supervised%2520learning.html">Generative supervised learning</a></u></h2><p>Learning the function <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi mathvariant="normal">∣</mi><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\text{input}|\text{output})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="text mord textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mord mathrm">∣</span><span class="text mord textstyle uncramped"><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mclose">)</span></span></span></span></span>, together with <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\text{output})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="text mord textstyle uncramped"><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mclose">)</span></span></span></span></span>, which can be used to find <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi mathvariant="normal">∣</mi><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\text{output}|\text{input})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="text mord textstyle uncramped"><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mord mathrm">∣</span><span class="text mord textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mclose">)</span></span></span></span></span> using <a class="tc-tiddlylink tc-tiddlylink-missing" href="Baye's%2520theorem.html">Baye's theorem</a>. 
See <a class="tc-tiddlylink-external" href="http://cs229.stanford.edu/notes/cs229-notes2.pdf" rel="noopener noreferrer" target="_blank">notes</a>. See <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;index=5&amp;list=PLA89DCFA6ADACE599#t=51s" rel="noopener noreferrer" target="_blank">lecture video</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;index=5&amp;list=PLA89DCFA6ADACE599#t=4m50s" rel="noopener noreferrer" target="_blank">def</a></p><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Gaussian%2520discriminant%2520analysis.html">Gaussian discriminant analysis</a></u></h3><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Naive%2520Bayes.html">Naive Bayes</a></u></h3></div>


</div>

</p>

</section>
</body>
</html>
