<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.12" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Supervised learning: Cosmos — a non-linear personal web notebook</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Machine%20learning"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible" title="More actions">


</button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible" title="Edit this tiddler">


</button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible" title="Close this tiddler">


</button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Supervised learning
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="guillefix.html">
guillefix
</a> 12th July 2016 at 12:32am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">

<button class="tc-btn-invisible tc-tag-label" style="background-color:;
fill:#333333;
color:#333333;">
 Machine learning
</button>
<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>Training data consisting on <strong>inputs and outputs</strong>.
<small>Other names for inputs: predictors, independent variables, features. Other names for outputs: responses, dependent variables.</small></p><p>In supervised learning, we want to find function relating inputs to outputs, to then be able to predict new outputs from new inputs. Need <strong>a way to represent the function approximation</strong>, with some parameters (the <strong>model</strong>). Some example of models:</p><ul><li>Linear functions</li><li>Kernel (basis) functions, polynomials, Gaussians, etc.</li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">Artificial neural network</a>s</li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Support%2520vector%2520machine.html">Support vector machine</a>s</li><li>Generative models.</li></ul><p>and a <strong>learning algorithm</strong> to find best parameters for the data, so that the model can predict well. See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Learning%2520theory.html">Learning theory</a>.</p><p>New paradigm: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning.html">Deep learning</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=oTtow2Ui8vg&amp;index=5&amp;list=PLD0F06AA0D2E8FFBA" rel="noopener noreferrer" target="_blank">Generative vs discriminative models</a></p><h2 class=""><u>Discriminative learning</u></h2><p>Learning the function <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi mathvariant="normal">∣</mi><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\text{output}|\text{input})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="text mord textstyle uncramped"><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mord mathrm">∣</span><span class="text mord textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mclose">)</span></span></span></span></span>. See <a class="tc-tiddlylink-external" href="http://cs229.stanford.edu/notes/cs229-notes1.pdf" rel="noopener noreferrer" target="_blank">notes</a></p><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Regression%2520analysis.html">Regression</a></u></h3><p>Output value is continuous, and quantiative (i.e. it has an ordering, and a notion of closeness (matrix)).</p><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Classification.html">Classification</a></u></h3><p>Output value is discrete, or categorical, or qualitative. No implicit ordering, or closeness on the variables. Simple approach: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Logistic%2520regression.html">Logistic regression</a></p><h3 class=""><u>General methods</u></h3><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">Artificial neural network</a> (see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning.html">Deep learning</a>)</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Support%2520vector%2520machine.html">Support vector machine</a></p><h2 class=""><u>Generative learning</u></h2><p>Learning the function <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi mathvariant="normal">∣</mi><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\text{input}|\text{output})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="text mord textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mord mathrm">∣</span><span class="text mord textstyle uncramped"><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mclose">)</span></span></span></span></span>, which can be used to find <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi mathvariant="normal">∣</mi><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\text{output}|\text{input})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="text mord textstyle uncramped"><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mord mathrm">∣</span><span class="text mord textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">p</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mclose">)</span></span></span></span></span> using <a class="tc-tiddlylink tc-tiddlylink-missing" href="Baye's%2520theorem.html">Baye's theorem</a>. 
See <a class="tc-tiddlylink-external" href="http://cs229.stanford.edu/notes/cs229-notes2.pdf" rel="noopener noreferrer" target="_blank">notes</a></p><h3 class=""><u>Gaussian discriminant analysis</u></h3><h3 class=""><u>Naive Bayes</u></h3><h1 class=""><u>Model assessment</u></h1><p>Variance. How much the model varies with fluctuations of the training data, i.e. how <em>stable</em> is it.</p><p>Bias. How many assumptions the model imposes, i.e. how <em>flexible</em> is it. Well that's maybe only one way to look at it..</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=JfkbyODyujw&amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;index=14#t=6m45s" rel="noopener noreferrer" target="_blank">See explanation here</a></p><h2 class=""><u>Cross-validation</u></h2><p>Test the model on data you haven't used for training.</p><p>min-max, average</p><p><a class="tc-tiddlylink tc-tiddlylink-missing" href="https%253A%252F%252Fwww.cs.cmu.edu%252F~schneide%252Ftut5%252Fnode42.html.html">https://www.cs.cmu.edu/~schneide/tut5/node42.html</a></p><p>Wikipedia has good explanations: <a class="tc-tiddlylink tc-tiddlylink-missing" href="https%253A%252F%252Fen.wikipedia.org%252Fwiki%252FCross-validation_(statistics).html">https://en.wikipedia.org/wiki/Cross-validation_(statistics)</a></p><p>One can show (maybe technical details I don't know..) that given the real distribution of the data, and a sample used for training, one is likely to underestimate the error. So I think cross-validation can be shown rigorously to be good for assessing a model's predictive power (i.e. probability of predicting rightly). See Elements of Statistical Learning book for all details..</p><p>It is a way to find out if you are overfitting</p><p>Related: <a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Testing_hypotheses_suggested_by_the_data" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Testing_hypotheses_suggested_by_the_data</a></p></div>



</div>

</p>

</section>
</body>
</html>
