<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Neural network theory: Cosmos — All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists  tc-tagged-Artificial%20neural%20network" data-tags="[[Artificial neural network]]" data-tiddler-title="Neural network theory"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Neural network theory
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 8th November 2018 at 8:17pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Artificial neural network
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p>The theory (mainly <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Learning%2520theory.html">Learning theory</a>) of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">Artificial neural network</a>s. See also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning%2520theory.html">Deep learning theory</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Mathematical%2520modelling%2520of%2520neural%2520networks.html">Mathematical modelling of neural networks</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Statistical%2520mechanics%2520of%2520neural%2520networks.html">Statistical mechanics of neural networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH" rel="noopener noreferrer" target="_blank">Neural networks class - Université de Sherbrooke (Hugo Larochelle)</a></p><p><small>Note that the notation in <a class="tc-tiddlylink-external" href="http://arxiv.org/abs/1608.08225" rel="noopener noreferrer" target="_blank">this paper</a> is opposite to that standard in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Machine%2520learning.html">Machine learning</a>. <u>In the paper, <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span></span> is the input, and <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span></span> is the output.</u>
</small></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Expressivity%2520of%2520neural%2520networks.html">Expressivity of neural networks</a></u></h2><h2 class=""><u>Learning of neural networks</u></h2><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Learning%2520theory.html">Learning theory</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">Artificial neural network</a>s, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Deep%2520learning%2520theory.html">Deep learning theory</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Non-convex%2520optimization.html">Non-convex optimization</a>...</p><h3 class=""><a class="tc-tiddlylink-external" href="https://gingkoapp.com/vehvff" rel="noopener noreferrer" target="_blank">Learning theory and neural networks gingko tree</a></h3><p>See talk at ICLR2017 by <a class="tc-tiddlylink-external" href="http://staff.polito.it/riccardo.zecchina/" rel="noopener noreferrer" target="_blank">Riccardo Zecchina</a></p><p><a class="tc-tiddlylink-external" href="http://iopscience.iop.org/article/10.1209/0295-5075/27/2/002/meta" rel="noopener noreferrer" target="_blank">Domains of Solutions and Replica Symmetry Breaking in Multilayer Neural Networks</a></p><p><a class="tc-tiddlylink-external" href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.75.2432" rel="noopener noreferrer" target="_blank">Weight Space Structure and Internal Representations: A Direct Approach to Learning and Generalization in Multilayer Neural Networks</a></p><p><a class="tc-tiddlylink-external" href="https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.115.128101" rel="noopener noreferrer" target="_blank">Subdominant Dense Clusters Allow for Simple Learning and High Computational Performance in Neural Networks with Discrete Synapses</a></p><p>Computational efficiency and optimization: <a class="tc-tiddlylink-external" href="https://pdfs.semanticscholar.org/a13e/ab6052cc9f85054d70d3ba395b0d77652172.pdf" rel="noopener noreferrer" target="_blank">Unreasonable effectiveness of learning neural nets: Accessible states and robust ensembles</a></p><h2 class=""><u>Generalization</u></h2><p><a class="tc-tiddlylink-external" href="https://dspace.mit.edu/handle/1721.1/107841" rel="noopener noreferrer" target="_blank">Theory of Deep Learning III: Generalization Properties of SGD</a></p><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generalization.html">Generalization</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generalization%2520in%2520deep%2520learning.html">Generalization in deep learning</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Statistical%2520physics%2520and%2520inference.html">Statistical physics and inference</a></p><p><small><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=hfBHELbk2Yw" rel="noopener noreferrer" target="_blank">Statistical mechanics of learning</a> </small></p><hr><p><a class="tc-tiddlylink-external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.6931&amp;rep=rep1&amp;type=pdf" rel="noopener noreferrer" target="_blank">Uniqueness of the weights for minimal feedforward nets with a given input-output map</a>,. <a class="tc-tiddlylink-external" href="https://www.researchgate.net/profile/Vera_Kurkova/publication/240374504_UNIQUENESS_OF_NETWORK_PARAMETERIZATIONS_AND_FASTER_LEARNING/links/547024480cf216f8cfa9e99e.pdf" rel="noopener noreferrer" target="_blank">more here</a></p><p><a class="tc-tiddlylink-external" href="http://ieeexplore.ieee.org/abstract/document/371799/" rel="noopener noreferrer" target="_blank">For neural networks, function determines form</a>, for 0-hidden layer, neural nets...</p><p><a class="tc-tiddlylink-external" href="http://www.mitpressjournals.org/doi/abs/10.1162/neco.1994.6.3.543?journalCode=neco" rel="noopener noreferrer" target="_blank">Functionally Equivalent Feedforward Neural Networks</a></p><p>See more at <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Singular%2520learning%2520theory.html">Singular learning theory</a></p><hr><p>Neural network dynamics, see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Dynamical%2520system.html">Dynamical system</a>s</p><p><a class="tc-tiddlylink-external" href="https://pearl.plymouth.ac.uk/handle/10026.1/8647" rel="noopener noreferrer" target="_blank">Dynamical Systems Theory for Transparent Symbolic Computation in Neuronal Networks</a> We show that a correspondence can be found between these networks and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Finite-state%2520transducer.html">Finite-state transducer</a>s, and use the derived abstraction to investigate how noise affects computation in this class of systems, unveiling a surprising facilitatory effect on information transmission.</p><p><a class="tc-tiddlylink-external" href="http://ieeexplore.ieee.org.sci-hub.cc/document/58339/" rel="noopener noreferrer" target="_blank">http://ieeexplore.ieee.org.sci-hub.cc/document/58339/</a>
</p></div>



</div>

</p>
</section>
</body>
</html>
