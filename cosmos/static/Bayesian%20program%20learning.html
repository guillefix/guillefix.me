<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Bayesian program learning: Cosmos — All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists  tc-tagged-Program%20induction" data-tags="[[Program induction]]" data-tiddler-title="Bayesian program learning"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Bayesian program learning
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 4th November 2016 at 2:43pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Program induction
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p>A type of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Program%2520induction.html">Program induction</a>, that can be used for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="One-shot%2520learning.html">One-shot learning</a></p><p><a class="tc-tiddlylink-external" href="http://cims.nyu.edu/~brenden/LakeEtAl2015Science.pdf" rel="noopener noreferrer" target="_blank">Human-level concept learning through probabilistic program induction</a></p><p>Concepts are represented as simple probabilistic programs—that is, probabilistic generative models expressed as structured procedures in an abstract description language (17,18). Our framework brings together three key ideas—compositionality, causality, and learning to learn—that have been separately influ-ential in cognitive science and machine learning over the past several decades (19–22).</p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Causality.html">Causality</a></u></h2><p>naturally captures the abstract “causal” structure of the real-world processes that produce examples of a category. </p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-missing" href="Learning%2520to%2520learn.html">Learning to learn</a></u></h2><p>Learning proceeds by constructing programs that best explain the observations under a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Bayesian%2520statistics.html">Bayesian</a> criterion, and the model “learns to learn” (23,24)  by developing hierarchical priors that allow previous experience with related concepts to ease learning of new concepts (25,26). These priors represent a learned inductive bias (27) that abstracts the key regularities and dimensions of variation holding across both types of concepts and across instances (or tokens) of a concept in a given domain. </p><p>In short, BPL can construct new programs by reusing the pieces of existing ones, capturing the causal and compositional properties of real-world generative processes operating on multiple scales. </p><h2 class=""><u>BPL</u></h2><p>BPL defines a generative model that can sam-ple new types of concepts (an“A,”“B,”etc.) by combining parts and subparts in new ways. Each new type is also represented as a genera-tive model, and this lower-level generative model produces new examples (or tokens) of the con-cept (Fig. 3A, v), making BPL a generative model for generative models. The final step renders the token-level variables in the format of the raw data</p><p>Could we decode representations structurally similar to those in BPL from brain imaging of premotor cortex (or otheraction-oriented regions) in humans perceiving and classifying new char-acters for the first time?</p></div>



</div>

</p>
</section>
</body>
</html>
