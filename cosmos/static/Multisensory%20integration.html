<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.17" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Multisensory integration: Cosmos â€” Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Cognitive%20neuroscience " data-tags="[[Cognitive neuroscience]]" data-tiddler-title="Multisensory integration"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Multisensory integration
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 12th August 2017 at 5:46pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Cognitive neuroscience
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>I had this idea! Well, I think there's still more work to do on artificial parietal cortices: neural networks for somato-sensory integration, i.e. combining the info from many different senses. I myself think that our semantic latent space in our minds is somewhere in the parietal lobe..</p><p>An architecture based on these ideas is what I hope could make a NN that can begin to generate realistic stories, which I think is a crucial part for AI. Things to include: has to be recurrent, multi-sensory integration into and from semantic latent space, attention. The training may be adversarial, though I think it may need to have some more advanced type of multi-modal context-dependent training (attention in training?). Also, metalearning/introspection (which I think in the brain resides in the frontal lobe) will be crucial. Finally, more advanced memory, like DNCs, will be necessary at some point (in the brain, hippocampus), but I don't yet know well how to do that.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Q6nYgeH8Krs" rel="noopener noreferrer" target="_blank">Unsupervised Learning of Spoken Language with Visual Context</a></p><p><a class="tc-tiddlylink-external" href="http://groups.csail.mit.edu/sls/publications/2016/FelixSun_SLT_2016.pdf" rel="noopener noreferrer" target="_blank">http://groups.csail.mit.edu/sls/publications/2016/FelixSun_SLT_2016.pdf</a></p><p>See facebook posts. CycleGAN.</p><p>multimodal learning, days fusion.</p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1704.03152" rel="noopener noreferrer" target="_blank">Deep Multimodal Representation Learning from Temporal Data</a></p><p><a class="tc-tiddlylink-external" href="http://people.csail.mit.edu/yusuf/see-hear-read//" rel="noopener noreferrer" target="_blank">See, Hear, and Read: Deep Aligned Representations</a></p></div>


</div>

</p>

</section>
</body>
</html>
