<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Generative adversarial network: Cosmos — All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists  tc-tagged-Generative%20model" data-tags="[[Generative model]]" data-tiddler-title="Generative adversarial network"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Generative adversarial network
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 31st March 2019 at 4:39am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Generative model
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p>An architecture to train generative neural networks, i.e. <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">neural networks</a> which act as <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generative%2520model.html">Generative model</a>s, i.e. their inputs are <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Latent%2520variable.html">Latent variable</a>s, and their output is the observed data.</p><p><a class="tc-tiddlylink-external" href="https://deephunt.in/the-gan-zoo-79597dc8c347" rel="noopener noreferrer" target="_blank">https://deephunt.in/the-gan-zoo-79597dc8c347</a> – <a class="tc-tiddlylink-external" href="https://github.com/wiseodd/generative-models" rel="noopener noreferrer" target="_blank">https://github.com/wiseodd/generative-models</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1701.00160.pdf" rel="noopener noreferrer" target="_blank">NIPS tutorial</a></p><p><a class="tc-tiddlylink-external" href="https://reiinakano.github.io/gan-playground/" rel="noopener noreferrer" target="_blank">GAN on browser</a></p><p>example of GANs for discrete data: <a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1611.08408.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1611.08408.pdf</a> (in area of semantic segmentation) It's funny how people in NLP literature keep talking about how GANs are hard to make work for discrete data. Then, people in image segmentation literature (oblivious of all this?) successfully apply vanilla GANs to discrete data..</p><h2 class=""><u>Adversarial networks</u></h2><p>The way the network is trained is by having the generative network produce images, while training a different discriminative network to discriminate between real and generated images. In this way, the discriminative network can be used as a very good cost function, which penalized generated images which are distinguishably different from the real images that the generative network is train to model. E.g. for NLP literature stuff <a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1611.04051?fbclid=IwAR0MOTB8nsV555rKdNb3EQ8pt-LbTKcxUHP_5ZC-of4zDGf_Et_uz1r39b4" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1611.04051?fbclid=IwAR0MOTB8nsV555rKdNb3EQ8pt-LbTKcxUHP_5ZC-of4zDGf_Et_uz1r39b4</a></p><p>We are in effect learning the cost function</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=14m30" rel="noopener noreferrer" target="_blank">video</a></p><h2 class=""><u>Trining GANs</u></h2><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=X1mUN6dD8uE" rel="noopener noreferrer" target="_blank">NIPS 2016 Workshop on Adversarial Training - Soumith Chintala - How to train a GAN</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=18m05" rel="noopener noreferrer" target="_blank">Trained</a> via <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Gradient%2520descent.html">Gradient descent</a> and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Backpropagation.html">Backpropagation</a></p><p>I think that the discriminator needs to have a separate cost function which measures the number of images the discriminator missclassified as being real or generated. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m47" rel="noopener noreferrer" target="_blank">Discriminator is optimized to not be fooled by the generator</a></p><p>On the other hand, the generative network uses the discriminative network as cost. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m20" rel="noopener noreferrer" target="_blank">Generator to fool discriminator, i.e. it is trained to maximize the mistakes the the discriminator does</a>, that's why they are called <strong>adversarial</strong></p><p>The discriminator is <em>teaching</em> the generator, and it's adapting to the generator's knowledge and flaws. <em>Machine teaching</em>, not just machine learning.</p><h3 class=""><u>Alternating <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Optimization.html">Optimization</a></u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m59" rel="noopener noreferrer" target="_blank">video</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1606.03498" rel="noopener noreferrer" target="_blank">Improved Techniques for Training GANs</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=45m30" rel="noopener noreferrer" target="_blank">vid</a></p><h2 class=""><u>Theoretical properties</u></h2><p>If you have an optimal discriminator, the generator minimizes the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Jensen-Shanon%2520divergence.html">Jensen-Shanon divergence</a></p><h2 class=""><u>Variants</u></h2><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=23m15" rel="noopener noreferrer" target="_blank">Original GANs were diffucult to train</a> </p><h3 class=""><u>Class-conditional GANs</u></h3><p>They are <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Supervised%2520learning.html">supervised</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1506.05751" rel="noopener noreferrer" target="_blank">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=24m" rel="noopener noreferrer" target="_blank">vid</a></p><h3 class=""><u>Video-prediction GANs</u></h3><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1511.05440" rel="noopener noreferrer" target="_blank">Deep multi-scale video prediction beyond mean square error</a>
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=25m45s" rel="noopener noreferrer" target="_blank">vid</a></p><h3 class=""><u>DCGANs</u></h3><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1511.06434" rel="noopener noreferrer" target="_blank">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=30m30s" rel="noopener noreferrer" target="_blank">Latent space arithmetic</a></p><h2 class=""><u>In-painting GANs</u></h2><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1604.07379" rel="noopener noreferrer" target="_blank">Context Encoders: Feature Learning by Inpainting</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=39m05" rel="noopener noreferrer" target="_blank">video</a></p><h2 class=""><u>Applications</u></h2><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Feature%2520learning.html">Feature learning</a> for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Semi-supervised%2520learning.html">Semi-supervised learning</a></u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=33m25" rel="noopener noreferrer" target="_blank">GANs for feature learning</a>. </p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=pqkpIfu36Os&amp;list=PLujxSBD-JXgnqDD1n-V30pKtp6Q886x7e&amp;index=108" rel="noopener noreferrer" target="_blank">Two Minute Papers - Image Editing with Generative Adversarial Networks</a></p><h3 class=""><u>Disentangling representations</u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=41m50s" rel="noopener noreferrer" target="_blank">vid</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1606.03657" rel="noopener noreferrer" target="_blank">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a> (from <a class="tc-tiddlylink tc-tiddlylink-missing" href="OpenAI.html">OpenAI</a>)</p><hr><p><a class="tc-tiddlylink-external" href="http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/" rel="noopener noreferrer" target="_blank">http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/</a></p><p>They are similar to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Autoencoder.html">Autoencoder</a>s but we learn the cost function, instead of just using l2 loss  (<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=58m50" rel="noopener noreferrer" target="_blank">vid</a>)</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=deyOX6Mt_As" rel="noopener noreferrer" target="_blank">vid</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1406.2661" rel="noopener noreferrer" target="_blank">Generative Adversarial Networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Generative_adversarial_networks" rel="noopener noreferrer" target="_blank">https://www.wikiwand.com/en/Generative_adversarial_networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=51m20" rel="noopener noreferrer" target="_blank">the future</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1610.01945" rel="noopener noreferrer" target="_blank">Connecting Generative Adversarial Networks and Actor-Critic Methods</a></p><hr><p>More variations and others</p><p>URL list from Sunday, May. 21 2017 16:41 PM</p><p>To copy this list, type [Ctrl] A, then type [Ctrl] C. </p><p>1603.08155.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1603.08155.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1603.08155.pdf</a></p><p>1703.10593.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1703.10593.pdf</a></p><p>1610.09003.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1610.09003.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1610.09003.pdf</a></p><p>RL Course by David Silver - Lecture 5: Model Free Control - YouTube
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;index=5&amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;index=5&amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT</a></p><p>Teaching
<a class="tc-tiddlylink-external" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="noopener noreferrer" target="_blank">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a></p><p>Lecture 1a - Introduction [Phil Blunsom] - YouTube
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm</a></p><p>[1612.03242] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1612.03242" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1612.03242</a></p><p>[1703.06412] TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06412" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06412</a></p><p>[1703.06676] I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06676" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06676</a></p><p>I2T2I: LEARNING TEXT TO IMAGE SYNTHESIS WITH TEXTUAL DATA AUGMENTATION
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1703.06676.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1703.06676.pdf</a></p><p>Generative Adversarial Text to Image Synthesis
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1605.05396.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1605.05396.pdf</a></p><p>Reed: Generative adversarial text to image synthesis - Google Scholar
<a class="tc-tiddlylink-external" href="https://scholar.google.co.uk/scholar?start=70&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;cites=8255440757806230750&amp;scipsc" rel="noopener noreferrer" target="_blank">https://scholar.google.co.uk/scholar?start=70&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;cites=8255440757806230750&amp;scipsc</a>=</p><p>Learning What and Where to Draw
<a class="tc-tiddlylink-external" href="http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw" rel="noopener noreferrer" target="_blank">http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw</a></p><p>Generating Visual Explanations | SpringerLink
<a class="tc-tiddlylink-external" href="https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1" rel="noopener noreferrer" target="_blank">https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1</a></p><p>[1609.09444] Contextual RNN-GANs for Abstract Reasoning Diagram Generation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1609.09444" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1609.09444</a></p><p>[1702.03431] Crossing Nets: Dual Generative Models with a Shared Latent Space for Hand Pose Estimation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1702.03431" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1702.03431</a></p><p>DISCO Nets : DISsimilarity COefficients Networks
<a class="tc-tiddlylink-external" href="http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks" rel="noopener noreferrer" target="_blank">http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks</a></p><p>[1704.06933] Adversarial Neural Machine Translation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1704.06933" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1704.06933</a></p><p>[1702.04125] One-Step Time-Dependent Future Video Frame Prediction with a Convolutional Encoder-Decoder Neural Network
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1702.04125" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1702.04125</a></p><p>[1703.06029] Towards Diverse and Natural Image Descriptions via a Conditional GAN
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06029" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06029</a></p><p>cvpr17_summarization.pdf
<a class="tc-tiddlylink-external" href="http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf" rel="noopener noreferrer" target="_blank">http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf</a></p><hr><p><a class="tc-tiddlylink-external" href="http://make.girls.moe/" rel="noopener noreferrer" target="_blank">http://make.girls.moe/</a>
</p></div>



</div>

</p>
</section>
</body>
</html>
