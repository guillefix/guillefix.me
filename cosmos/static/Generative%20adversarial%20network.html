<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.15" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Generative adversarial network: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Generative%20model"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Generative adversarial network
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 6th November 2017 at 10:26pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Generative model
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>An architecture to train generative neural networks, i.e. <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">neural networks</a> which act as <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Generative%2520model.html">Generative model</a>s, i.e. their inputs are <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Latent%2520variable.html">Latent variable</a>s, and their output is the observed data.</p><p><a class="tc-tiddlylink-external" href="https://deephunt.in/the-gan-zoo-79597dc8c347" rel="noopener noreferrer" target="_blank">https://deephunt.in/the-gan-zoo-79597dc8c347</a> – <a class="tc-tiddlylink-external" href="https://github.com/wiseodd/generative-models" rel="noopener noreferrer" target="_blank">https://github.com/wiseodd/generative-models</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1701.00160.pdf" rel="noopener noreferrer" target="_blank">NIPS tutorial</a></p><p><a class="tc-tiddlylink-external" href="https://reiinakano.github.io/gan-playground/" rel="noopener noreferrer" target="_blank">GAN on browser</a></p><h2 class=""><u>Adversarial networks</u></h2><p>The way the network is trained is by having the generative network produce images, while training a different discriminative network to discriminate between real and generated images. In this way, the discriminative network can be used as a very good cost function, which penalized generated images which are distinguishably different from the real images that the generative network is train to model.</p><p>We are in effect learning the cost function</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=14m30" rel="noopener noreferrer" target="_blank">video</a></p><h2 class=""><u>Trining GANs</u></h2><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=X1mUN6dD8uE" rel="noopener noreferrer" target="_blank">NIPS 2016 Workshop on Adversarial Training - Soumith Chintala - How to train a GAN</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=18m05" rel="noopener noreferrer" target="_blank">Trained</a> via <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Gradient%2520descent.html">Gradient descent</a> and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Backpropagation.html">Backpropagation</a></p><p>I think that the discriminator needs to have a separate cost function which measures the number of images the discriminator missclassified as being real or generated. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m47" rel="noopener noreferrer" target="_blank">Discriminator is optimized to not be fooled by the generator</a></p><p>On the other hand, the generative network uses the discriminative network as cost. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m20" rel="noopener noreferrer" target="_blank">Generator to fool discriminator, i.e. it is trained to maximize the mistakes the the discriminator does</a>, that's why they are called <strong>adversarial</strong></p><p>The discriminator is <em>teaching</em> the generator, and it's adapting to the generator's knowledge and flaws. <em>Machine teaching</em>, not just machine learning.</p><h3 class=""><u>Alternating <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Optimization.html">Optimization</a></u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m59" rel="noopener noreferrer" target="_blank">video</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1606.03498" rel="noopener noreferrer" target="_blank">Improved Techniques for Training GANs</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=45m30" rel="noopener noreferrer" target="_blank">vid</a></p><h2 class=""><u>Theoretical properties</u></h2><p>If you have an optimal discriminator, the generator minimizes the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Jensen-Shanon%2520divergence.html">Jensen-Shanon divergence</a></p><h2 class=""><u>Variants</u></h2><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=23m15" rel="noopener noreferrer" target="_blank">Original GANs were diffucult to train</a> </p><h3 class=""><u>Class-conditional GANs</u></h3><p>They are <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Supervised%2520learning.html">supervised</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1506.05751" rel="noopener noreferrer" target="_blank">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=24m" rel="noopener noreferrer" target="_blank">vid</a></p><h3 class=""><u>Video-prediction GANs</u></h3><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1511.05440" rel="noopener noreferrer" target="_blank">Deep multi-scale video prediction beyond mean square error</a>
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=25m45s" rel="noopener noreferrer" target="_blank">vid</a></p><h3 class=""><u>DCGANs</u></h3><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1511.06434" rel="noopener noreferrer" target="_blank">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=30m30s" rel="noopener noreferrer" target="_blank">Latent space arithmetic</a></p><h2 class=""><u>In-painting GANs</u></h2><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1604.07379" rel="noopener noreferrer" target="_blank">Context Encoders: Feature Learning by Inpainting</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=39m05" rel="noopener noreferrer" target="_blank">video</a></p><h2 class=""><u>Applications</u></h2><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Feature%2520learning.html">Feature learning</a> for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Semi-supervised%2520learning.html">Semi-supervised learning</a></u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=33m25" rel="noopener noreferrer" target="_blank">GANs for feature learning</a>. </p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=pqkpIfu36Os&amp;list=PLujxSBD-JXgnqDD1n-V30pKtp6Q886x7e&amp;index=108" rel="noopener noreferrer" target="_blank">Two Minute Papers - Image Editing with Generative Adversarial Networks</a></p><h3 class=""><u>Disentangling representations</u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=41m50s" rel="noopener noreferrer" target="_blank">vid</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1606.03657" rel="noopener noreferrer" target="_blank">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a> (from <a class="tc-tiddlylink tc-tiddlylink-missing" href="OpenAI.html">OpenAI</a>)</p><hr><p><a class="tc-tiddlylink-external" href="http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/" rel="noopener noreferrer" target="_blank">http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/</a></p><p>They are similar to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Autoencoder.html">Autoencoder</a>s but we learn the cost function, instead of just using l2 loss  (<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=58m50" rel="noopener noreferrer" target="_blank">vid</a>)</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=deyOX6Mt_As" rel="noopener noreferrer" target="_blank">vid</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1406.2661" rel="noopener noreferrer" target="_blank">Generative Adversarial Networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Generative_adversarial_networks" rel="noopener noreferrer" target="_blank">https://www.wikiwand.com/en/Generative_adversarial_networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=51m20" rel="noopener noreferrer" target="_blank">the future</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1610.01945" rel="noopener noreferrer" target="_blank">Connecting Generative Adversarial Networks and Actor-Critic Methods</a></p><hr><p>More variations and others</p><p>URL list from Sunday, May. 21 2017 16:41 PM</p><p>To copy this list, type [Ctrl] A, then type [Ctrl] C. </p><p>1603.08155.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1603.08155.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1603.08155.pdf</a></p><p>1703.10593.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1703.10593.pdf</a></p><p>1610.09003.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1610.09003.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1610.09003.pdf</a></p><p>RL Course by David Silver - Lecture 5: Model Free Control - YouTube
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;index=5&amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;index=5&amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT</a></p><p>Teaching
<a class="tc-tiddlylink-external" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="noopener noreferrer" target="_blank">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a></p><p>Lecture 1a - Introduction [Phil Blunsom] - YouTube
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm</a></p><p>[1612.03242] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1612.03242" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1612.03242</a></p><p>[1703.06412] TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06412" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06412</a></p><p>[1703.06676] I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06676" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06676</a></p><p>I2T2I: LEARNING TEXT TO IMAGE SYNTHESIS WITH TEXTUAL DATA AUGMENTATION
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1703.06676.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1703.06676.pdf</a></p><p>Generative Adversarial Text to Image Synthesis
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1605.05396.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1605.05396.pdf</a></p><p>Reed: Generative adversarial text to image synthesis - Google Scholar
<a class="tc-tiddlylink-external" href="https://scholar.google.co.uk/scholar?start=70&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;cites=8255440757806230750&amp;scipsc" rel="noopener noreferrer" target="_blank">https://scholar.google.co.uk/scholar?start=70&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;cites=8255440757806230750&amp;scipsc</a>=</p><p>Learning What and Where to Draw
<a class="tc-tiddlylink-external" href="http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw" rel="noopener noreferrer" target="_blank">http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw</a></p><p>Generating Visual Explanations | SpringerLink
<a class="tc-tiddlylink-external" href="https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1" rel="noopener noreferrer" target="_blank">https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1</a></p><p>[1609.09444] Contextual RNN-GANs for Abstract Reasoning Diagram Generation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1609.09444" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1609.09444</a></p><p>[1702.03431] Crossing Nets: Dual Generative Models with a Shared Latent Space for Hand Pose Estimation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1702.03431" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1702.03431</a></p><p>DISCO Nets : DISsimilarity COefficients Networks
<a class="tc-tiddlylink-external" href="http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks" rel="noopener noreferrer" target="_blank">http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks</a></p><p>[1704.06933] Adversarial Neural Machine Translation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1704.06933" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1704.06933</a></p><p>[1702.04125] One-Step Time-Dependent Future Video Frame Prediction with a Convolutional Encoder-Decoder Neural Network
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1702.04125" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1702.04125</a></p><p>[1703.06029] Towards Diverse and Natural Image Descriptions via a Conditional GAN
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06029" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06029</a></p><p>cvpr17_summarization.pdf
<a class="tc-tiddlylink-external" href="http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf" rel="noopener noreferrer" target="_blank">http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf</a></p><hr><p><a class="tc-tiddlylink-external" href="http://make.girls.moe/" rel="noopener noreferrer" target="_blank">http://make.girls.moe/</a>
</p></div>


</div>

</p>

</section>
</body>
</html>
