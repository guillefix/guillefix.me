<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.15" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Causality: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Inference"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Causality
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 19th November 2018 at 7:38pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Inference
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>Cause –&gt; Effect</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Bayesian%2520network.html">Bayesian network</a>s
– <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Causal%2520inference.html">Causal inference</a></p><p><strong>Causality</strong> refers to structural properties (e.g. <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Independence.html">Independence</a> relations) of a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Bayesian%2520network.html">Bayesian network</a> modeling a system, which includes variables relevant to any possible experiment which involves that system, specially experiments involving <em>intervention</em>. The issue is that one can't in general infer the whole Bayesian network from a single, or even many experiments, unless one makes assumptions. A common assumption is the &quot;effective <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Free%2520will.html">Free will</a>&quot; assumption, which assumes that the choice of the experimenter is independent of any relevant variables; this rules out <a class="tc-tiddlylink tc-tiddlylink-missing" href="Superdeterminism.html">superdeterminist</a> explanations. This assumption is often not quite true, and to correct it, we use methods such as double-blindness in trials, etc.</p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Judea_Pearl" rel="noopener noreferrer" target="_blank">Judea Pearl</a></p><p><a class="tc-tiddlylink-external" href="http://www.goodreads.com/book/show/174276.Causality" rel="noopener noreferrer" target="_blank">Causality: Models, Reasoning, and Inference</a></p><p><a class="tc-tiddlylink-external" href="http://bayes.cs.ucla.edu/PRIMER/" rel="noopener noreferrer" target="_blank">http://bayes.cs.ucla.edu/PRIMER/</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=uzDUc8xmYYY" rel="noopener noreferrer" target="_blank">[Коллоквиум]: Causal inference and Kolmogorov complexity</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Randomized%2520controlled%2520trial.html">Randomized controlled trial</a>s are used to infer causal relations.</p><hr><p><a class="tc-tiddlylink-external" href="http://www.mdpi.com/1099-4300/19/5/188" rel="noopener noreferrer" target="_blank">When the Map Is Better Than the Territory</a> uses <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Mutual%2520information.html">Mutual information</a> as a measure of causal influence (he talks about causal <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Emergence.html">Emergence</a>). He finds that the mutual information at higher scales can be higher than those at lower scales. This may sound counterintuitive. Mutual information is defined as how much information does an intervention give you on the future state of a system, i.e. how much does knowing which intervention is performed determine the future of a system, versus not knowing it. However, crucially, mutual information is defined as the <em>average</em> of this quantity over interventions. And in particular, he defines as the average when the distribution is uniform over interventions.</p><p>So, if we are talking about intervening at a small scale (the &quot;territory&quot;), by his definition, we consider all possible interventions with equal probability (note intervention is defined as setting the system in a particular state before letting it evolve). If most of these interventions don't determine the future much, then in average we won't determine the future much.</p><p>What does intervening at a higher scale (the &quot;map&quot;) means? It means, for example, intervening now on a set of <em>macrostates</em>, which correspond to sets of microstates. <strong>Crucially</strong>, an uniform distribution on macrostates, can cause a non-uniform distribution on microstates. In particular, it can put much more weight on those microstates that effectively determined the future. Therefore this macro intervention will have higher causal influence.</p><p>This doesn't mean it's impossible to have as much causal influence in the micro scale, we could just choose the non-uniform distribution at that scale. But it means that in some sense, the macroscale can give us that for free, making the job much easier, and it's thus better in that respect.</p><p>He makes some connections to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Channel%2520capacity.html">Channel capacity</a> which I haven't looked at in much detail.</p><p>Some philosophical points at the end seem like they are stretching the implications a bit too much. But I do see this possibly giving insight into questions of emergence</p></div>


</div>

</p>

</section>
</body>
</html>
