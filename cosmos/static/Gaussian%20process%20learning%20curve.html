<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Gaussian process learning curve: Cosmos â€” All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists  tc-tagged-Learning%20curve tc-tagged-Gaussian%20process" data-tags="[[Learning curve]] [[Gaussian process]]" data-tiddler-title="Gaussian process learning curve"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Gaussian process learning curve
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 10th December 2019 at 6:47pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Gaussian process
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span><span class="tc-tag-list-item">
<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Learning curve
</span>
<span class="tc-drop-down tc-reveal" hidden="true"></span></span></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p><a class="tc-tiddlylink-external" href="https://papers.nips.cc/paper/1501-learning-curves-for-gaussian-processes.pdf" rel="noopener noreferrer" target="_blank">Learning curves for Gaussian processes</a></p><p>Recent analysis for non-well specified case for traslationally-invariant kernels: <a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1905.10843" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1905.10843</a></p><hr><p>Can apply, for instance to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Neural%2520network%2520Gaussian%2520process.html">Neural network Gaussian process</a></p><hr><p>Need to find eigenfunctions of kernel, under some data distribution:</p><p>See my thoughts (and initial confusion) in <a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1907.10599.pdf" rel="noopener noreferrer" target="_blank">this paper</a> (see hypothes.is) (that paper also finds eigenfunctions of the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="NNGP.html">NNGP</a> kernel for some simple input distributions)</p><p>How does this definition of the kernel as an integral operator fit in the rest of the story as a kernel of a Gaussian process? I thought a Gaussian process doesn't define an input over functions?</p><p>No, but this still has implications. Clearly, the expected generalization behaviour depends on the input distribution. This can be seen in the langauge of GPs, by noticing that the orthogonal basis under different distributions, when restricted to the training set, would stay approximately orthogonal, and approximately diagonalize the empirical kernel, only if the training set is sampled from the input distribution defining the basis. So that if we don't use the right basis, then it will tell us what the bias is, but in a way that may not be very relevant for the data distribution we have. For example, imagine that we have input data distribution that is a Gaussian. We don't care about the fact that we may be biased towards functions that wiggle one way or the other, far away from the origin. We want to bundle together all functions that behave similarly near the origin. The right basis/inner product achieves by giving small inner product to &quot;similar&quot; functions, and making the basis vectors to be maximially dissimilar, therefore capturing the essence of functions, as they matter for the expected data distribution.</p><p>A more quantitative version of the reason why they matter, is that the basis matching the input distribution, gives the simplest expression for the expected generalization error, as explained, e.g., here: <a class="tc-tiddlylink-external" href="https://papers.nips.cc/paper/1501-learning-curves-for-gaussian-processes.pdf" rel="noopener noreferrer" target="_blank">https://papers.nips.cc/paper/1501-learning-curves-for-gaussian-processes.pdf</a></p></div>



</div>

</p>
</section>
</body>
</html>
