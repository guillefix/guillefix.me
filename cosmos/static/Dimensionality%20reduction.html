<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.17" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Dimensionality reduction: Cosmos — Everything there was, there is, and there will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Unsupervised%20learning " data-tags="[[Unsupervised learning]]" data-tiddler-title="Dimensionality reduction"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="tiddlymap" class="tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton " title="Toggle TiddlyMap actions">


</button></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Dimensionality reduction
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 5th September 2017 at 6:30pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-tag-label tc-btn-invisible" draggable="true" style="background-color:;
fill:#333333;
color:#333333;">
 Unsupervised learning
</span>

<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><p>A type of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Unsupervised%2520learning.html">Unsupervised learning</a> where we describe the data using less features (called latent factors) than the data was initially described with.</p><p><a class="tc-tiddlylink-external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.453.8815" rel="noopener noreferrer" target="_blank">Graph embedding and extensions: A general framework for dimensionality reduction</a>. Basically minimize <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mo>∑</mo><mrow><mi>i</mi><mo>≠</mo><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mi>y</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><msup><mi mathvariant="normal">∣</mi><mrow><mn>2</mn></mrow></msup><msub><mi>W</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\sum_{i \neq j} ||y_i -y_j||^{2} W_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.264618em;vertical-align:-0.45050999999999997em;"></span><span class="base textstyle uncramped"><span class="mop"><span class="op-symbol small-op mop" style="top:-0.0000050000000000050004em;">∑</span><span class="vlist"><span style="top:0.30001em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mrel">≠</span><span class="mord mathit" style="margin-right:0.05724em;">j</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∣</span><span class="mord mathrm">∣</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">−</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.05724em;">j</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∣</span><span class="mord"><span class="mord mathrm">∣</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathrm">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.05724em;">j</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p><p>See also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Feature%2520learning.html">Feature learning</a>, which is very similar.</p><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Factor%2520analysis%2520model.html">Factor analysis model</a></u></h3><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Linear%2520discriminant%2520analysis.html">Linear discriminant analysis</a></u></h3><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Principal%2520component%2520analysis.html">Principal component analysis</a></u></h3><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Multidimensional%2520scaling.html">Multidimensional scaling</a></u></h3><p><a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Multidimensional_scaling" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Multidimensional_scaling</a></p><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Locality%2520preserving%2520projection.html">Locality preserving projection</a></u></h3><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Manifold%2520learning.html">Manifold learning</a></u></h3><p><a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Laplacian_eigenmaps" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Laplacian_eigenmaps</a></p><hr><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Nonparametric%2520statistics.html">Non-parametric models</a> are suitable especially for a scenario that all the data points in the source space are known or available and the embedding task needs to be undertaken on a given data set without the need of extension to unseen data points during learning. This is a salient characteristic that distinguishes between parametric and non-parametric subspace learning. As a typical non-parametric subspace learning framework, multi-dimensional scaling (MDS) (Cox and Cox 2000) refers to a family of algorithms that learn embedding a set of given high-dimensional data points into a low-dimensional subspace by preserving the distance information between data points in the high-dimensional space. Sammon mapping (Sammon 1969) is an effective non-linear MDS algorithm.</p><p>The fact that it works is related to the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Sloppy%2520systems.html">Sloppy systems</a> and the <a class="tc-tiddlylink tc-tiddlylink-missing" href="Manifold%2520hypothesis.html">Manifold hypothesis</a>, and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Simplicity%2520bias.html">Simplicity bias</a></p><hr><h3 class=""><u>Incremental algorithms (<a class="tc-tiddlylink tc-tiddlylink-resolves" href="Online%2520learning.html">Online learning</a>)</u></h3><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S016786550900213X?np=y&amp;npKey=a7379a552798ed3cc17a1cfb6ef118a83b9304ec725b827b3449a6898cc8f8bc" rel="noopener noreferrer" target="_blank">Incremental Laplacian eigenmaps by preserving adjacent information between data points</a></p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S0167865511001048?np=y&amp;npKey=a7379a552798ed3cd01dc0579657be210f27d523e4ac61e53b81eb388b94a047" rel="noopener noreferrer" target="_blank">Incremental manifold learning by spectral embedding methods</a></p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S0031320313002732" rel="noopener noreferrer" target="_blank">Embedding new observations via sparse-coding for non-linear manifold learning</a></p><p><a class="tc-tiddlylink-external" href="https://link.springer.com/chapter/10.1007/978-3-319-46182-3_5" rel="noopener noreferrer" target="_blank">Incremental Construction of Low-Dimensional Data Representations</a></p><p>A New Manifold Learning Algorithm Based on Incremental Spectral Decomposition</p><hr><p><a class="tc-tiddlylink-external" href="https://link.springer.com/article/10.1007/s13735-015-0079-y" rel="noopener noreferrer" target="_blank">Learning to detect concepts with Approximate Laplacian Eigenmaps in large-scale and online settings</a></p></div>


</div>

</p>

</section>
</body>
</html>
