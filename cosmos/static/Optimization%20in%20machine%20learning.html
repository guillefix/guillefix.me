<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.21" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Optimization in machine learning: Cosmos — All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists " data-tags="" data-tiddler-title="Optimization in machine learning"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Optimization in machine learning
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 13th May 2019 at 7:24pm
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"></div>
</div>

<div class="tc-tiddler-body tc-reveal"><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Optimization%2520for%2520learning.html">Optimization for learning</a></p><p><u>Algorithms</u></p><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Gradient%2520descent.html">Gradient descent</a> <ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Stochastic%2520gradient%2520descent.html">Stochastic gradient descent</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Newton's%2520method.html">Newton's method</a></li></ul></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="EM%2520algorithm.html">EM algorithm</a></li></ul><h2 class=""><u>Parameter initialization</u></h2><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sLfogkzFNfc&amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;index=15" rel="noopener noreferrer" target="_blank">Neural networks [2.9] : Training neural networks - parameter initialization</a></p><h2 class=""><u>Batch learning</u></h2><p>The most common procedure, described above and in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Machine%2520learning.html">Machine learning</a>, where the algorithm is run on a particular data set all at once.</p><h3 class=""><u>Mini-batch learning</u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Bver7Ttgb9M&amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;index=17#t=11m37s" rel="noopener noreferrer" target="_blank">video</a>. Performing the optimization algo on a sample of a given size from the data set, per iteration.</p><h3 class=""><u>Momentum</u></h3><p>To get through plateaus, for instance.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=0qUAb94CpOw&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=6#t=50m40s" rel="noopener noreferrer" target="_blank">Momentum</a>. You add inertia to the particle so that the gradient descent is not just velocity = gradient (as it'd be in viscous fluid), but it is acceleration = (viscosity) + gradient.</p><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Backpropagation.html">Backpropagation</a></u></h3><p>for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Artificial%2520neural%2520network.html">Artificial neural network</a>s</p><h2 class=""><u>Online learning</u></h2><p>as opposed to <em>batch learning</em></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=17m30s" rel="noopener noreferrer" target="_blank">video</a>. You have to make predictions even in the process of learning.</p><p><sub>
(<em>Online algorithm</em>, you process the data sequentially, by chunks. You need this if you do not access to all of it at the same time, or you have so much data that not all of it fits on your RAM..)
</sub></p><p>What we care about is the <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=19m25s" rel="noopener noreferrer" target="_blank">online error</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=19m57s" rel="noopener noreferrer" target="_blank">Can apply batch learning algos for online learning</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=21m58s" rel="noopener noreferrer" target="_blank">Several theoretical results exist</a></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Simplicity%2520and%2520learning.html">Simplicity and learning</a></u></h2><p>The simplicity and structure in signals in the real-world is often seized to make the learning problem easier to solve.</p><h2 class=""><u><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=24m55s" rel="noopener noreferrer" target="_blank">Advice for applying machine learning algorithms</a></u></h2><h3 class=""><u><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=28m37s" rel="noopener noreferrer" target="_blank">Diagnosis for debugging learning algorithms</a></u></h3><p>Diagnostic:</p><ul><li>High variance (overfitting) -&gt; Training error would be much lower than test error. (<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=34m05s" rel="noopener noreferrer" target="_blank">video</a>)</li><li>High bias (underfitting) -&gt; Test error will also be high. (<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=35m50s" rel="noopener noreferrer" target="_blank">video</a>)</li></ul><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=37m50s" rel="noopener noreferrer" target="_blank">Ways to fix high variance or bias</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=37m50s" rel="noopener noreferrer" target="_blank">Is the algo converging?</a> – <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=43m30s" rel="noopener noreferrer" target="_blank">Are you optimizing the right function?</a> –&gt; <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=45m" rel="noopener noreferrer" target="_blank">Diagnostic</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=50m45s" rel="noopener noreferrer" target="_blank">One more example</a></p><h3 class=""><u><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=1h03m20s" rel="noopener noreferrer" target="_blank">Error analysis</a> and <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=1h08m48s" rel="noopener noreferrer" target="_blank">ablative analysis</a></u></h3><h3 class=""><u><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=1h11m45s" rel="noopener noreferrer" target="_blank">How to get started on a machine learning problem</a></u></h3><p>– Premature (statistical) optimization (<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=27m30s" rel="noopener noreferrer" target="_blank">video</a>)</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=1h16m45s" rel="noopener noreferrer" target="_blank">The dangers of over-theorizing</a></p><h3 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Optimization%2520for%2520training%2520deep%2520models.html">Optimization for training deep models</a></h3></div>



</div>

</p>
</section>
</body>
</html>
