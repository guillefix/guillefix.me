<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.15" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>Maximum likelihood: Cosmos — All that is, or was, or ever will be</title>
</head>
<body class="tc-body">

<section class="tc-story-river">

<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   "><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Maximum likelihood
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="cosmos.html">
cosmos
</a> 31st March 2019 at 4:08am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"></div>
</div>
<div class="tc-tiddler-body tc-reveal"><p><em>aka maximum likelihood estimation, MLE</em></p><p><strong>Minimize a cost function</strong>, which often is the negative log <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Likelihood%2520function.html">likelihood</a> (similar to entropy. More precisely, cross-entropy, or relative entropy), which corresponds to <strong>maximizing likelihood</strong>. Likelihood is the probability of getting the right <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span></span> given <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span></span>, i.e. the probability that a given model predicts the right outputs. This is equivalent to finding the most likely <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span></span> in the Bayesian posterior, given a flat prior (but if we add a <strong>regularizer</strong>, we can tweak the prior, by just adding a term to the log likelihood). If our model uses a Gaussian distribution to predict the data (where the <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span></span>s are the means), maximizing likelihood is equivalent to minimizing spring energy for springs vertically placed between fit curve and data.</p><p>The maximum likelihood is found by <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Optimization.html">Optimization</a>, often by <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Stochastic%2520gradient%2520descent.html">Stochastic gradient descent</a>.</p><p>If we want the whole distribution of likelihoods over <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span></span>s, we need to use Bayesian statistics, which involves doing complicated integrals, often done numerically using <a class="tc-tiddlylink tc-tiddlylink-missing" href="Montecarlo%2520methods.html">Montecarlo methods</a></p><p>See <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=HZ4cvaztQEs&amp;index=3&amp;list=PLA89DCFA6ADACE599#t=43m20s" rel="noopener noreferrer" target="_blank">video</a></p><p>Too see the application of this method in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Supervised%2520learning.html">Supervised learning</a> see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Discriminative%2520learning.html">Discriminative learning</a>, and <a class="tc-tiddlylink tc-tiddlylink-missing" href="Generative%2520learning.html">Generative learning</a></p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Maximum_likelihood_estimation" rel="noopener noreferrer" target="_blank">https://www.wikiwand.com/en/Maximum_likelihood_estimation</a></p><h3 class=""><u>MLE via <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Variational%2520inference.html">Variational inference</a></u></h3><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="Variational%2520inference.html">Variational inference</a></p></div>


</div>

</p>

</section>
</body>
</html>
